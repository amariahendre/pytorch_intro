{"cells":[{"source":"# Introduction to Deep Learning with PyTorch","metadata":{},"cell_type":"markdown","id":"613c3a02-7d6d-46f8-984a-80a60f471500"},{"source":"## Basic informations about tensors","metadata":{},"cell_type":"markdown","id":"ce04b23d-5ee1-4e1d-91c0-0420560bd84f"},{"source":"import torch\nimport numpy as np","metadata":{"id":"bA5ajAmk7XH6","executionTime":50,"lastSuccessfullyExecutedCode":"import torch\nimport numpy as np"},"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","cell_type":"code","execution_count":17,"outputs":[]},{"source":"# create a tensor from a list\narray = [[1,2,3],[4,5,6]]\ntensor = torch.tensor(array)\ntensor","metadata":{"executionTime":43,"lastSuccessfullyExecutedCode":"# create a tensor from a list\narray = [[1,2,3],[4,5,6]]\ntensor = torch.tensor(array)\ntensor"},"cell_type":"code","id":"c438b727-78cb-45eb-882d-afdadd5d1c1c","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"tensor([[1, 2, 3],\n        [4, 5, 6]])"},"metadata":{}}]},{"source":"# create a tensor from a NumPy arra\nnp_array = np.array(array)\nnp_tensor = torch.from_numpy(np_array)\nnp_tensor","metadata":{"executionTime":46,"lastSuccessfullyExecutedCode":"# create a tensor from a NumPy arra\nnp_array = np.array(array)\nnp_tensor = torch.from_numpy(np_array)\nnp_tensor"},"cell_type":"code","id":"e35d577e-6e40-4adf-8247-49a852bb03ac","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"tensor([[1, 2, 3],\n        [4, 5, 6]])"},"metadata":{}}]},{"source":"# tensor attributes\ntensor.device, tensor.shape, tensor.dtype","metadata":{"executionTime":49,"lastSuccessfullyExecutedCode":"# tensor attributes\ntensor.device, tensor.shape, tensor.dtype"},"cell_type":"code","id":"1630fc76-bf94-4f57-9f28-6ac7df29e7ce","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(device(type='cpu'), torch.Size([2, 3]), torch.int64)"},"metadata":{}}]},{"source":"# tensor operations (The size of tensor a must match the size of tensor b)\na = torch.tensor([[1,1],[2,2]]) \nb = torch.tensor([[2,2],[3,3]])\n# addition/substraction/multiplication/divizion\na+b, a-b, a*b, a/b","metadata":{"executionTime":38,"lastSuccessfullyExecutedCode":"# tensor operations (The size of tensor a must match the size of tensor b)\na = torch.tensor([[1,1],[2,2]]) \nb = torch.tensor([[2,2],[3,3]])\n# addition/substraction/multiplication/divizion\na+b, a-b, a*b, a/b"},"cell_type":"code","id":"5f609947-3f7f-48f4-93e3-892f2d5c296c","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"(tensor([[3, 3],\n         [5, 5]]),\n tensor([[-1, -1],\n         [-1, -1]]),\n tensor([[2, 2],\n         [6, 6]]),\n tensor([[0.5000, 0.5000],\n         [0.6667, 0.6667]]))"},"metadata":{}}]},{"source":"## Roadmap to training a neural network","metadata":{},"cell_type":"markdown","id":"ec986f11-cc00-4c4f-952d-025e84ce3231"},{"source":"1. Create an architecture of the nerural network (see an example bellow) ![nn_architecture](nn_architecture.png)\n2. Load data using PyTorch\n3. Define the loss function (Measures difference between model predictions and true labels; Used to assess the accuracy of our model; Accuracy is determined by weights and biases, which are parameters learned during model training; They denote strength and direction of connections between individual neurons.)\n4. Set up an optimizer (Optimizer will update network weights during training; SGD most used)\n5. Define a training loop (Pass input data through network to gain initial predictions, i.e. run a forward pass; Compute loss using loss function; Run backpropagation to compute gradients, which determine how much each neuron contributed to overall error in final output; Update weights and biases using the gradients)\n6. Test the trained network on a separate dataset to evaluate performance (Define metrics to test usefulness of our predictions on validation and test sets)\n","metadata":{},"cell_type":"markdown","id":"bd694fce-efbd-4df4-bebe-8d23c1c93975"},{"source":"### 1. Create a neural network","metadata":{},"cell_type":"markdown","id":"a476a8fc-6004-4f37-8625-c4ead5c40939"},{"source":"**PyTorch implementation of a neural network with three layers.**\n\n- The input layer has 8 neurons and is represented by nn.Linear(8, 4), which means that it takes an input with 8 features and outputs a tensor with 4 values.\n- The first hidden layer is represented by nn.Sigmoid(), which applies the sigmoid activation function to the output of the input layer.\n- The second hidden layer has 2 neurons and is represented by nn.Linear(4, 2), which takes the output of the first hidden layer as input and outputs a tensor with 2 values.\n- The second hidden layer is followed by another nn.Sigmoid() activation function.\n- The output layer has only 1 neuron and is represented by nn.Linear(2, 1), which takes the output of the second hidden layer as input and produces a scalar value as output.\n- The final nn.Sigmoid() activation function is applied to the output of the output layer, which maps the output to a value between 0 and 1, making it suitable for binary classification tasks.\n\nThe network bellow has three layers with sigmoid activation functions, which makes it suitable for classification problems where the output is a binary variable.","metadata":{},"cell_type":"markdown","id":"a5d11d87-c258-44d4-bade-fe337675b49a"},{"source":"import torch.nn as nn\n\nmodel = nn.Sequential(nn.Linear(8, 4),\n                      nn.Sigmoid(),\n                      nn.Linear(4, 2),\n                      nn.Sigmoid(),\n                      nn.Linear(2, 1),\n                      nn.Sigmoid())\n\ninput_tensor = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\noutput = model(input_tensor)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"import torch.nn as nn\n\nmodel = nn.Sequential(nn.Linear(8, 4),\n                      nn.Sigmoid(),\n                      nn.Linear(4, 2),\n                      nn.Sigmoid(),\n                      nn.Linear(2, 1),\n                      nn.Sigmoid())\n\ninput_tensor = torch.Tensor([[1, 2, 3, 4, 5, 6, 7, 8]])\noutput = model(input_tensor)"},"cell_type":"code","id":"32cba4bc-8bf4-4d28-a87a-74655edac3a1","execution_count":22,"outputs":[]},{"source":"Note: A neural network with only one layer can be similar to logistic regression if the activation function used in the output layer is the sigmoid function. In this case, the neural network is essentially a logistic regression model with additional trainable parameters.\n\nInput and output layers dimensions are fixed (input layer depends on the number of features n_features; output layer depends on the number of categories n_classes). Increasing the number of hidden layers = increasing the number of parameters = increasing the model capacity.","metadata":{},"cell_type":"markdown","id":"d2ae294b-d936-41cd-80a0-3cf3c253dd4e"},{"source":"### 2. Load data in PyTorch","metadata":{},"cell_type":"markdown","id":"d498e580-7473-4015-8a6c-b9c723cbbd45"},{"source":"# Import libraries\nfrom torch.utils.data import Dataset\nimport pandas as pd\nfrom torch.utils.data import DataLoader, TensorDataset","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Import libraries\nfrom torch.utils.data import Dataset\nimport pandas as pd\nfrom torch.utils.data import DataLoader, TensorDataset"},"cell_type":"code","id":"5c123d3b-3e64-4f3e-b3a5-7671591d29ee","execution_count":23,"outputs":[]},{"source":"# Create a PyTorch Dataset class that reads a CSV file and provides a method for extracting features and labels for a given index.\n\nclass MyDataset(Dataset):\n    def __init__(self, csv_path):\n        \"\"\"\n        A PyTorch dataset for loading data from a CSV file.\n        \n        Parameters:\n            csv_path (str): The path to the CSV file.\n        \n        Returns:\n            None\n        \"\"\"\n        super(MyDataset, self).__init__()\n        self.data = pd.read_csv(csv_path).to_numpy()\n        \n    def __len__(self):\n        \"\"\"\n        Get the number of samples in the dataset.\n        \n        Parameters:\n            None\n        \n        Returns:\n            int: The number of samples in the dataset.\n        \"\"\"\n        return self.data.shape[0]\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Get the features and label of a sample at a given index.\n        \n        Parameters:\n            index (int): The index of the sample to retrieve.\n        \n        Returns:\n            tuple: A tuple containing the features (as a tensor) and label (as a tensor) of the sample.\n        \"\"\"\n        features, label = self.extract_features_and_label(index)\n        return features, label\n    \n    def extract_features_and_label(self, index):\n        \"\"\"\n        Extract the features and label of a sample at a given index.\n        \n        Parameters:\n            index (int): The index of the sample to retrieve.\n        \n        Returns:\n            tuple: A tuple containing the features (as a tensor) and label (as a tensor) of the sample.\n        \"\"\"\n        row = self.data[index]\n        features = row[:-1].astype(np.float32)\n        label = torch.tensor(row[-1])\n        return torch.from_numpy(features), torch.tensor(label)","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Create a PyTorch Dataset class that reads a CSV file and provides a method for extracting features and labels for a given index.\n\nclass MyDataset(Dataset):\n    def __init__(self, csv_path):\n        \"\"\"\n        A PyTorch dataset for loading data from a CSV file.\n        \n        Parameters:\n            csv_path (str): The path to the CSV file.\n        \n        Returns:\n            None\n        \"\"\"\n        super(MyDataset, self).__init__()\n        self.data = pd.read_csv(csv_path).to_numpy()\n        \n    def __len__(self):\n        \"\"\"\n        Get the number of samples in the dataset.\n        \n        Parameters:\n            None\n        \n        Returns:\n            int: The number of samples in the dataset.\n        \"\"\"\n        return self.data.shape[0]\n    \n    def __getitem__(self, index):\n        \"\"\"\n        Get the features and label of a sample at a given index.\n        \n        Parameters:\n            index (int): The index of the sample to retrieve.\n        \n        Returns:\n            tuple: A tuple containing the features (as a tensor) and label (as a tensor) of the sample.\n        \"\"\"\n        features, label = self.extract_features_and_label(index)\n        return features, label\n    \n    def extract_features_and_label(self, index):\n        \"\"\"\n        Extract the features and label of a sample at a given index.\n        \n        Parameters:\n            index (int): The index of the sample to retrieve.\n        \n        Returns:\n            tuple: A tuple containing the features (as a tensor) and label (as a tensor) of the sample.\n        \"\"\"\n        row = self.data[index]\n        features = row[:-1].astype(np.float32)\n        label = torch.tensor(row[-1])\n        return torch.from_numpy(features), torch.tensor(label)"},"cell_type":"code","id":"35144ff1-e794-4919-93b8-fcbbad969a0d","execution_count":24,"outputs":[]},{"source":"# Create an instance of the MyDataset class and a DataLoader to load the data in batches.\ndataset = MyDataset('water_potability.csv')\ndataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n\n# Iterates over the DataLoader to extract features and labels in batches, and prints the shape of the features and labels in each batch. \nfor batch_idx, (features, label) in enumerate(dataloader):\n    print(f'Batch {batch_idx}: {features.shape}, {label.shape}')\n\n# Extract the first batch of features and labels using the next function.\nx, y = next(iter(dataloader))","metadata":{"executionTime":82,"lastSuccessfullyExecutedCode":"# Create an instance of the MyDataset class and a DataLoader to load the data in batches.\ndataset = MyDataset('water_potability.csv')\ndataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n\n# Iterates over the DataLoader to extract features and labels in batches, and prints the shape of the features and labels in each batch. \nfor batch_idx, (features, label) in enumerate(dataloader):\n    print(f'Batch {batch_idx}: {features.shape}, {label.shape}')\n\n# Extract the first batch of features and labels using the next function.\nx, y = next(iter(dataloader))"},"cell_type":"code","id":"44b36241-6eff-462d-ae53-ee9d80824840","execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":"Batch 0: torch.Size([2, 9]), torch.Size([2])\nBatch 1: torch.Size([2, 9]), torch.Size([2])\nBatch 2: torch.Size([2, 9]), torch.Size([2])\nBatch 3: torch.Size([2, 9]), torch.Size([2])\nBatch 4: torch.Size([2, 9]), torch.Size([2])\nBatch 5: torch.Size([2, 9]), torch.Size([2])\nBatch 6: torch.Size([2, 9]), torch.Size([2])\nBatch 7: torch.Size([2, 9]), torch.Size([2])\nBatch 8: torch.Size([2, 9]), torch.Size([2])\nBatch 9: torch.Size([2, 9]), torch.Size([2])\nBatch 10: torch.Size([2, 9]), torch.Size([2])\nBatch 11: torch.Size([2, 9]), torch.Size([2])\nBatch 12: torch.Size([2, 9]), torch.Size([2])\nBatch 13: torch.Size([2, 9]), torch.Size([2])\nBatch 14: torch.Size([2, 9]), torch.Size([2])\nBatch 15: torch.Size([2, 9]), torch.Size([2])\nBatch 16: torch.Size([2, 9]), torch.Size([2])\nBatch 17: torch.Size([2, 9]), torch.Size([2])\nBatch 18: torch.Size([2, 9]), torch.Size([2])\nBatch 19: torch.Size([2, 9]), torch.Size([2])\nBatch 20: torch.Size([2, 9]), torch.Size([2])\nBatch 21: torch.Size([2, 9]), torch.Size([2])\nBatch 22: torch.Size([2, 9]), torch.Size([2])\nBatch 23: torch.Size([2, 9]), torch.Size([2])\nBatch 24: torch.Size([2, 9]), torch.Size([2])\nBatch 25: torch.Size([2, 9]), torch.Size([2])\nBatch 26: torch.Size([2, 9]), torch.Size([2])\nBatch 27: torch.Size([2, 9]), torch.Size([2])\nBatch 28: torch.Size([2, 9]), torch.Size([2])\nBatch 29: torch.Size([2, 9]), torch.Size([2])\nBatch 30: torch.Size([2, 9]), torch.Size([2])\nBatch 31: torch.Size([2, 9]), torch.Size([2])\nBatch 32: torch.Size([2, 9]), torch.Size([2])\nBatch 33: torch.Size([2, 9]), torch.Size([2])\nBatch 34: torch.Size([2, 9]), torch.Size([2])\nBatch 35: torch.Size([2, 9]), torch.Size([2])\nBatch 36: torch.Size([2, 9]), torch.Size([2])\nBatch 37: torch.Size([2, 9]), torch.Size([2])\nBatch 38: torch.Size([2, 9]), torch.Size([2])\nBatch 39: torch.Size([2, 9]), torch.Size([2])\nBatch 40: torch.Size([2, 9]), torch.Size([2])\nBatch 41: torch.Size([2, 9]), torch.Size([2])\nBatch 42: torch.Size([2, 9]), torch.Size([2])\nBatch 43: torch.Size([2, 9]), torch.Size([2])\nBatch 44: torch.Size([2, 9]), torch.Size([2])\nBatch 45: torch.Size([2, 9]), torch.Size([2])\nBatch 46: torch.Size([2, 9]), torch.Size([2])\nBatch 47: torch.Size([2, 9]), torch.Size([2])\nBatch 48: torch.Size([2, 9]), torch.Size([2])\nBatch 49: torch.Size([2, 9]), torch.Size([2])\nBatch 50: torch.Size([2, 9]), torch.Size([2])\nBatch 51: torch.Size([2, 9]), torch.Size([2])\nBatch 52: torch.Size([2, 9]), torch.Size([2])\nBatch 53: torch.Size([2, 9]), torch.Size([2])\nBatch 54: torch.Size([2, 9]), torch.Size([2])\nBatch 55: torch.Size([2, 9]), torch.Size([2])\nBatch 56: torch.Size([2, 9]), torch.Size([2])\nBatch 57: torch.Size([2, 9]), torch.Size([2])\nBatch 58: torch.Size([2, 9]), torch.Size([2])\nBatch 59: torch.Size([2, 9]), torch.Size([2])\nBatch 60: torch.Size([2, 9]), torch.Size([2])\nBatch 61: torch.Size([2, 9]), torch.Size([2])\nBatch 62: torch.Size([2, 9]), torch.Size([2])\nBatch 63: torch.Size([2, 9]), torch.Size([2])\nBatch 64: torch.Size([2, 9]), torch.Size([2])\nBatch 65: torch.Size([2, 9]), torch.Size([2])\nBatch 66: torch.Size([2, 9]), torch.Size([2])\nBatch 67: torch.Size([2, 9]), torch.Size([2])\nBatch 68: torch.Size([2, 9]), torch.Size([2])\nBatch 69: torch.Size([2, 9]), torch.Size([2])\nBatch 70: torch.Size([2, 9]), torch.Size([2])\nBatch 71: torch.Size([2, 9]), torch.Size([2])\nBatch 72: torch.Size([2, 9]), torch.Size([2])\nBatch 73: torch.Size([2, 9]), torch.Size([2])\nBatch 74: torch.Size([2, 9]), torch.Size([2])\nBatch 75: torch.Size([2, 9]), torch.Size([2])\nBatch 76: torch.Size([2, 9]), torch.Size([2])\nBatch 77: torch.Size([2, 9]), torch.Size([2])\nBatch 78: torch.Size([2, 9]), torch.Size([2])\nBatch 79: torch.Size([2, 9]), torch.Size([2])\nBatch 80: torch.Size([2, 9]), torch.Size([2])\nBatch 81: torch.Size([2, 9]), torch.Size([2])\nBatch 82: torch.Size([2, 9]), torch.Size([2])\nBatch 83: torch.Size([2, 9]), torch.Size([2])\nBatch 84: torch.Size([2, 9]), torch.Size([2])\nBatch 85: torch.Size([2, 9]), torch.Size([2])\nBatch 86: torch.Size([2, 9]), torch.Size([2])\nBatch 87: torch.Size([2, 9]), torch.Size([2])\nBatch 88: torch.Size([2, 9]), torch.Size([2])\nBatch 89: torch.Size([2, 9]), torch.Size([2])\nBatch 90: torch.Size([2, 9]), torch.Size([2])\nBatch 91: torch.Size([2, 9]), torch.Size([2])\nBatch 92: torch.Size([2, 9]), torch.Size([2])\nBatch 93: torch.Size([2, 9]), torch.Size([2])\nBatch 94: torch.Size([2, 9]), torch.Size([2])\nBatch 95: torch.Size([2, 9]), torch.Size([2])\nBatch 96: torch.Size([2, 9]), torch.Size([2])\nBatch 97: torch.Size([2, 9]), torch.Size([2])\nBatch 98: torch.Size([2, 9]), torch.Size([2])\nBatch 99: torch.Size([2, 9]), torch.Size([2])\nBatch 100: torch.Size([2, 9]), torch.Size([2])\nBatch 101: torch.Size([2, 9]), torch.Size([2])\nBatch 102: torch.Size([2, 9]), torch.Size([2])\nBatch 103: torch.Size([2, 9]), torch.Size([2])\nBatch 104: torch.Size([2, 9]), torch.Size([2])\nBatch 105: torch.Size([2, 9]), torch.Size([2])\nBatch 106: torch.Size([2, 9]), torch.Size([2])\nBatch 107: torch.Size([2, 9]), torch.Size([2])\nBatch 108: torch.Size([2, 9]), torch.Size([2])\nBatch 109: torch.Size([2, 9]), torch.Size([2])\nBatch 110: torch.Size([2, 9]), torch.Size([2])\nBatch 111: torch.Size([2, 9]), torch.Size([2])\nBatch 112: torch.Size([2, 9]), torch.Size([2])\nBatch 113: torch.Size([2, 9]), torch.Size([2])\nBatch 114: torch.Size([2, 9]), torch.Size([2])\nBatch 115: torch.Size([2, 9]), torch.Size([2])\nBatch 116: torch.Size([2, 9]), torch.Size([2])\nBatch 117: torch.Size([2, 9]), torch.Size([2])\nBatch 118: torch.Size([2, 9]), torch.Size([2])\nBatch 119: torch.Size([2, 9]), torch.Size([2])\nBatch 120: torch.Size([2, 9]), torch.Size([2])\nBatch 121: torch.Size([2, 9]), torch.Size([2])\nBatch 122: torch.Size([2, 9]), torch.Size([2])\nBatch 123: torch.Size([2, 9]), torch.Size([2])\nBatch 124: torch.Size([2, 9]), torch.Size([2])\nBatch 125: torch.Size([2, 9]), torch.Size([2])\nBatch 126: torch.Size([2, 9]), torch.Size([2])\nBatch 127: torch.Size([2, 9]), torch.Size([2])\nBatch 128: torch.Size([2, 9]), torch.Size([2])\nBatch 129: torch.Size([2, 9]), torch.Size([2])\nBatch 130: torch.Size([2, 9]), torch.Size([2])\nBatch 131: torch.Size([2, 9]), torch.Size([2])\nBatch 132: torch.Size([2, 9]), torch.Size([2])\nBatch 133: torch.Size([2, 9]), torch.Size([2])\nBatch 134: torch.Size([2, 9]), torch.Size([2])\nBatch 135: torch.Size([2, 9]), torch.Size([2])\nBatch 136: torch.Size([2, 9]), torch.Size([2])\nBatch 137: torch.Size([2, 9]), torch.Size([2])\nBatch 138: torch.Size([2, 9]), torch.Size([2])\nBatch 139: torch.Size([2, 9]), torch.Size([2])\nBatch 140: torch.Size([2, 9]), torch.Size([2])\nBatch 141: torch.Size([2, 9]), torch.Size([2])\nBatch 142: torch.Size([2, 9]), torch.Size([2])\nBatch 143: torch.Size([2, 9]), torch.Size([2])\nBatch 144: torch.Size([2, 9]), torch.Size([2])\nBatch 145: torch.Size([2, 9]), torch.Size([2])\nBatch 146: torch.Size([2, 9]), torch.Size([2])\nBatch 147: torch.Size([2, 9]), torch.Size([2])\nBatch 148: torch.Size([2, 9]), torch.Size([2])\nBatch 149: torch.Size([2, 9]), torch.Size([2])\nBatch 150: torch.Size([2, 9]), torch.Size([2])\nBatch 151: torch.Size([2, 9]), torch.Size([2])\nBatch 152: torch.Size([2, 9]), torch.Size([2])\nBatch 153: torch.Size([2, 9]), torch.Size([2])\nBatch 154: torch.Size([2, 9]), torch.Size([2])\nBatch 155: torch.Size([2, 9]), torch.Size([2])\nBatch 156: torch.Size([2, 9]), torch.Size([2])\nBatch 157: torch.Size([2, 9]), torch.Size([2])\nBatch 158: torch.Size([2, 9]), torch.Size([2])\nBatch 159: torch.Size([2, 9]), torch.Size([2])\nBatch 160: torch.Size([2, 9]), torch.Size([2])\nBatch 161: torch.Size([2, 9]), torch.Size([2])\nBatch 162: torch.Size([2, 9]), torch.Size([2])\nBatch 163: torch.Size([2, 9]), torch.Size([2])\nBatch 164: torch.Size([2, 9]), torch.Size([2])\nBatch 165: torch.Size([2, 9]), torch.Size([2])\nBatch 166: torch.Size([2, 9]), torch.Size([2])\nBatch 167: torch.Size([2, 9]), torch.Size([2])\nBatch 168: torch.Size([2, 9]), torch.Size([2])\nBatch 169: torch.Size([2, 9]), torch.Size([2])\nBatch 170: torch.Size([2, 9]), torch.Size([2])\nBatch 171: torch.Size([2, 9]), torch.Size([2])\nBatch 172: torch.Size([2, 9]), torch.Size([2])\nBatch 173: torch.Size([2, 9]), torch.Size([2])\nBatch 174: torch.Size([2, 9]), torch.Size([2])\nBatch 175: torch.Size([2, 9]), torch.Size([2])\nBatch 176: torch.Size([2, 9]), torch.Size([2])\nBatch 177: torch.Size([2, 9]), torch.Size([2])\nBatch 178: torch.Size([2, 9]), torch.Size([2])\nBatch 179: torch.Size([2, 9]), torch.Size([2])\nBatch 180: torch.Size([2, 9]), torch.Size([2])\nBatch 181: torch.Size([2, 9]), torch.Size([2])\nBatch 182: torch.Size([2, 9]), torch.Size([2])\nBatch 183: torch.Size([2, 9]), torch.Size([2])\nBatch 184: torch.Size([2, 9]), torch.Size([2])\nBatch 185: torch.Size([2, 9]), torch.Size([2])\nBatch 186: torch.Size([2, 9]), torch.Size([2])\nBatch 187: torch.Size([2, 9]), torch.Size([2])\nBatch 188: torch.Size([2, 9]), torch.Size([2])\nBatch 189: torch.Size([2, 9]), torch.Size([2])\nBatch 190: torch.Size([2, 9]), torch.Size([2])\nBatch 191: torch.Size([2, 9]), torch.Size([2])\nBatch 192: torch.Size([2, 9]), torch.Size([2])\nBatch 193: torch.Size([2, 9]), torch.Size([2])\nBatch 194: torch.Size([2, 9]), torch.Size([2])\nBatch 195: torch.Size([2, 9]), torch.Size([2])\nBatch 196: torch.Size([2, 9]), torch.Size([2])\nBatch 197: torch.Size([2, 9]), torch.Size([2])\nBatch 198: torch.Size([2, 9]), torch.Size([2])\nBatch 199: torch.Size([2, 9]), torch.Size([2])\nBatch 200: torch.Size([2, 9]), torch.Size([2])\nBatch 201: torch.Size([2, 9]), torch.Size([2])\nBatch 202: torch.Size([2, 9]), torch.Size([2])\nBatch 203: torch.Size([2, 9]), torch.Size([2])\nBatch 204: torch.Size([2, 9]), torch.Size([2])\nBatch 205: torch.Size([2, 9]), torch.Size([2])\nBatch 206: torch.Size([2, 9]), torch.Size([2])\nBatch 207: torch.Size([2, 9]), torch.Size([2])\nBatch 208: torch.Size([2, 9]), torch.Size([2])\nBatch 209: torch.Size([2, 9]), torch.Size([2])\nBatch 210: torch.Size([2, 9]), torch.Size([2])\nBatch 211: torch.Size([2, 9]), torch.Size([2])\nBatch 212: torch.Size([2, 9]), torch.Size([2])\nBatch 213: torch.Size([2, 9]), torch.Size([2])\nBatch 214: torch.Size([2, 9]), torch.Size([2])\nBatch 215: torch.Size([2, 9]), torch.Size([2])\nBatch 216: torch.Size([2, 9]), torch.Size([2])\nBatch 217: torch.Size([2, 9]), torch.Size([2])\nBatch 218: torch.Size([2, 9]), torch.Size([2])\nBatch 219: torch.Size([2, 9]), torch.Size([2])\nBatch 220: torch.Size([2, 9]), torch.Size([2])\nBatch 221: torch.Size([2, 9]), torch.Size([2])\nBatch 222: torch.Size([2, 9]), torch.Size([2])\nBatch 223: torch.Size([2, 9]), torch.Size([2])\nBatch 224: torch.Size([2, 9]), torch.Size([2])\nBatch 225: torch.Size([2, 9]), torch.Size([2])\nBatch 226: torch.Size([2, 9]), torch.Size([2])\nBatch 227: torch.Size([2, 9]), torch.Size([2])\nBatch 228: torch.Size([2, 9]), torch.Size([2])\nBatch 229: torch.Size([2, 9]), torch.Size([2])\nBatch 230: torch.Size([2, 9]), torch.Size([2])\nBatch 231: torch.Size([2, 9]), torch.Size([2])\nBatch 232: torch.Size([2, 9]), torch.Size([2])\nBatch 233: torch.Size([2, 9]), torch.Size([2])\nBatch 234: torch.Size([2, 9]), torch.Size([2])\nBatch 235: torch.Size([2, 9]), torch.Size([2])\nBatch 236: torch.Size([2, 9]), torch.Size([2])\nBatch 237: torch.Size([2, 9]), torch.Size([2])\nBatch 238: torch.Size([2, 9]), torch.Size([2])\nBatch 239: torch.Size([2, 9]), torch.Size([2])\nBatch 240: torch.Size([2, 9]), torch.Size([2])\nBatch 241: torch.Size([2, 9]), torch.Size([2])\nBatch 242: torch.Size([2, 9]), torch.Size([2])\nBatch 243: torch.Size([2, 9]), torch.Size([2])\nBatch 244: torch.Size([2, 9]), torch.Size([2])\nBatch 245: torch.Size([2, 9]), torch.Size([2])\nBatch 246: torch.Size([2, 9]), torch.Size([2])\nBatch 247: torch.Size([2, 9]), torch.Size([2])\nBatch 248: torch.Size([2, 9]), torch.Size([2])\nBatch 249: torch.Size([2, 9]), torch.Size([2])\nBatch 250: torch.Size([2, 9]), torch.Size([2])\nBatch 251: torch.Size([2, 9]), torch.Size([2])\nBatch 252: torch.Size([2, 9]), torch.Size([2])\nBatch 253: torch.Size([2, 9]), torch.Size([2])\nBatch 254: torch.Size([2, 9]), torch.Size([2])\nBatch 255: torch.Size([2, 9]), torch.Size([2])\nBatch 256: torch.Size([2, 9]), torch.Size([2])\nBatch 257: torch.Size([2, 9]), torch.Size([2])\nBatch 258: torch.Size([2, 9]), torch.Size([2])\nBatch 259: torch.Size([2, 9]), torch.Size([2])\nBatch 260: torch.Size([2, 9]), torch.Size([2])\nBatch 261: torch.Size([2, 9]), torch.Size([2])\nBatch 262: torch.Size([2, 9]), torch.Size([2])\nBatch 263: torch.Size([2, 9]), torch.Size([2])\nBatch 264: torch.Size([2, 9]), torch.Size([2])\nBatch 265: torch.Size([2, 9]), torch.Size([2])\nBatch 266: torch.Size([2, 9]), torch.Size([2])\nBatch 267: torch.Size([2, 9]), torch.Size([2])\nBatch 268: torch.Size([2, 9]), torch.Size([2])\nBatch 269: torch.Size([2, 9]), torch.Size([2])\nBatch 270: torch.Size([2, 9]), torch.Size([2])\nBatch 271: torch.Size([2, 9]), torch.Size([2])\nBatch 272: torch.Size([2, 9]), torch.Size([2])\nBatch 273: torch.Size([2, 9]), torch.Size([2])\nBatch 274: torch.Size([2, 9]), torch.Size([2])\nBatch 275: torch.Size([2, 9]), torch.Size([2])\nBatch 276: torch.Size([2, 9]), torch.Size([2])\nBatch 277: torch.Size([2, 9]), torch.Size([2])\nBatch 278: torch.Size([2, 9]), torch.Size([2])\nBatch 279: torch.Size([2, 9]), torch.Size([2])\nBatch 280: torch.Size([2, 9]), torch.Size([2])\nBatch 281: torch.Size([2, 9]), torch.Size([2])\nBatch 282: torch.Size([2, 9]), torch.Size([2])\nBatch 283: torch.Size([2, 9]), torch.Size([2])\nBatch 284: torch.Size([2, 9]), torch.Size([2])\nBatch 285: torch.Size([2, 9]), torch.Size([2])\nBatch 286: torch.Size([2, 9]), torch.Size([2])\nBatch 287: torch.Size([2, 9]), torch.Size([2])\nBatch 288: torch.Size([2, 9]), torch.Size([2])\nBatch 289: torch.Size([2, 9]), torch.Size([2])\nBatch 290: torch.Size([2, 9]), torch.Size([2])\nBatch 291: torch.Size([2, 9]), torch.Size([2])\nBatch 292: torch.Size([2, 9]), torch.Size([2])\nBatch 293: torch.Size([2, 9]), torch.Size([2])\nBatch 294: torch.Size([2, 9]), torch.Size([2])\nBatch 295: torch.Size([2, 9]), torch.Size([2])\nBatch 296: torch.Size([2, 9]), torch.Size([2])\nBatch 297: torch.Size([2, 9]), torch.Size([2])\nBatch 298: torch.Size([2, 9]), torch.Size([2])\nBatch 299: torch.Size([2, 9]), torch.Size([2])\nBatch 300: torch.Size([2, 9]), torch.Size([2])\nBatch 301: torch.Size([2, 9]), torch.Size([2])\nBatch 302: torch.Size([2, 9]), torch.Size([2])\nBatch 303: torch.Size([2, 9]), torch.Size([2])\nBatch 304: torch.Size([2, 9]), torch.Size([2])\nBatch 305: torch.Size([2, 9]), torch.Size([2])\nBatch 306: torch.Size([2, 9]), torch.Size([2])\nBatch 307: torch.Size([2, 9]), torch.Size([2])\nBatch 308: torch.Size([2, 9]), torch.Size([2])\nBatch 309: torch.Size([2, 9]), torch.Size([2])\nBatch 310: torch.Size([2, 9]), torch.Size([2])\nBatch 311: torch.Size([2, 9]), torch.Size([2])\nBatch 312: torch.Size([2, 9]), torch.Size([2])\nBatch 313: torch.Size([2, 9]), torch.Size([2])\nBatch 314: torch.Size([2, 9]), torch.Size([2])\nBatch 315: torch.Size([2, 9]), torch.Size([2])\nBatch 316: torch.Size([2, 9]), torch.Size([2])\nBatch 317: torch.Size([2, 9]), torch.Size([2])\nBatch 318: torch.Size([2, 9]), torch.Size([2])\nBatch 319: torch.Size([2, 9]), torch.Size([2])\nBatch 320: torch.Size([2, 9]), torch.Size([2])\nBatch 321: torch.Size([2, 9]), torch.Size([2])\nBatch 322: torch.Size([2, 9]), torch.Size([2])\nBatch 323: torch.Size([2, 9]), torch.Size([2])\nBatch 324: torch.Size([2, 9]), torch.Size([2])\nBatch 325: torch.Size([2, 9]), torch.Size([2])\nBatch 326: torch.Size([2, 9]), torch.Size([2])\nBatch 327: torch.Size([2, 9]), torch.Size([2])\nBatch 328: torch.Size([2, 9]), torch.Size([2])\nBatch 329: torch.Size([2, 9]), torch.Size([2])\nBatch 330: torch.Size([2, 9]), torch.Size([2])\nBatch 331: torch.Size([2, 9]), torch.Size([2])\nBatch 332: torch.Size([2, 9]), torch.Size([2])\nBatch 333: torch.Size([2, 9]), torch.Size([2])\nBatch 334: torch.Size([2, 9]), torch.Size([2])\nBatch 335: torch.Size([2, 9]), torch.Size([2])\nBatch 336: torch.Size([2, 9]), torch.Size([2])\nBatch 337: torch.Size([2, 9]), torch.Size([2])\nBatch 338: torch.Size([2, 9]), torch.Size([2])\nBatch 339: torch.Size([2, 9]), torch.Size([2])\nBatch 340: torch.Size([2, 9]), torch.Size([2])\nBatch 341: torch.Size([2, 9]), torch.Size([2])\nBatch 342: torch.Size([2, 9]), torch.Size([2])\nBatch 343: torch.Size([2, 9]), torch.Size([2])\nBatch 344: torch.Size([2, 9]), torch.Size([2])\nBatch 345: torch.Size([2, 9]), torch.Size([2])\nBatch 346: torch.Size([2, 9]), torch.Size([2])\nBatch 347: torch.Size([2, 9]), torch.Size([2])\nBatch 348: torch.Size([2, 9]), torch.Size([2])\nBatch 349: torch.Size([2, 9]), torch.Size([2])\nBatch 350: torch.Size([2, 9]), torch.Size([2])\nBatch 351: torch.Size([2, 9]), torch.Size([2])\nBatch 352: torch.Size([2, 9]), torch.Size([2])\nBatch 353: torch.Size([2, 9]), torch.Size([2])\nBatch 354: torch.Size([2, 9]), torch.Size([2])\nBatch 355: torch.Size([2, 9]), torch.Size([2])\nBatch 356: torch.Size([2, 9]), torch.Size([2])\nBatch 357: torch.Size([2, 9]), torch.Size([2])\nBatch 358: torch.Size([2, 9]), torch.Size([2])\nBatch 359: torch.Size([2, 9]), torch.Size([2])\nBatch 360: torch.Size([2, 9]), torch.Size([2])\nBatch 361: torch.Size([2, 9]), torch.Size([2])\nBatch 362: torch.Size([2, 9]), torch.Size([2])\nBatch 363: torch.Size([2, 9]), torch.Size([2])\nBatch 364: torch.Size([2, 9]), torch.Size([2])\nBatch 365: torch.Size([2, 9]), torch.Size([2])\nBatch 366: torch.Size([2, 9]), torch.Size([2])\nBatch 367: torch.Size([2, 9]), torch.Size([2])\nBatch 368: torch.Size([2, 9]), torch.Size([2])\nBatch 369: torch.Size([2, 9]), torch.Size([2])\nBatch 370: torch.Size([2, 9]), torch.Size([2])\nBatch 371: torch.Size([2, 9]), torch.Size([2])\nBatch 372: torch.Size([2, 9]), torch.Size([2])\nBatch 373: torch.Size([2, 9]), torch.Size([2])\nBatch 374: torch.Size([2, 9]), torch.Size([2])\nBatch 375: torch.Size([2, 9]), torch.Size([2])\nBatch 376: torch.Size([2, 9]), torch.Size([2])\nBatch 377: torch.Size([2, 9]), torch.Size([2])\nBatch 378: torch.Size([2, 9]), torch.Size([2])\nBatch 379: torch.Size([2, 9]), torch.Size([2])\nBatch 380: torch.Size([2, 9]), torch.Size([2])\nBatch 381: torch.Size([2, 9]), torch.Size([2])\nBatch 382: torch.Size([2, 9]), torch.Size([2])\nBatch 383: torch.Size([2, 9]), torch.Size([2])\nBatch 384: torch.Size([2, 9]), torch.Size([2])\nBatch 385: torch.Size([2, 9]), torch.Size([2])\nBatch 386: torch.Size([2, 9]), torch.Size([2])\nBatch 387: torch.Size([2, 9]), torch.Size([2])\nBatch 388: torch.Size([2, 9]), torch.Size([2])\nBatch 389: torch.Size([2, 9]), torch.Size([2])\nBatch 390: torch.Size([2, 9]), torch.Size([2])\nBatch 391: torch.Size([2, 9]), torch.Size([2])\nBatch 392: torch.Size([2, 9]), torch.Size([2])\nBatch 393: torch.Size([2, 9]), torch.Size([2])\nBatch 394: torch.Size([2, 9]), torch.Size([2])\nBatch 395: torch.Size([2, 9]), torch.Size([2])\nBatch 396: torch.Size([2, 9]), torch.Size([2])\nBatch 397: torch.Size([2, 9]), torch.Size([2])\nBatch 398: torch.Size([2, 9]), torch.Size([2])\nBatch 399: torch.Size([2, 9]), torch.Size([2])\nBatch 400: torch.Size([2, 9]), torch.Size([2])\nBatch 401: torch.Size([2, 9]), torch.Size([2])\nBatch 402: torch.Size([2, 9]), torch.Size([2])\nBatch 403: torch.Size([2, 9]), torch.Size([2])\nBatch 404: torch.Size([2, 9]), torch.Size([2])\nBatch 405: torch.Size([2, 9]), torch.Size([2])\nBatch 406: torch.Size([2, 9]), torch.Size([2])\nBatch 407: torch.Size([2, 9]), torch.Size([2])\nBatch 408: torch.Size([2, 9]), torch.Size([2])\nBatch 409: torch.Size([2, 9]), torch.Size([2])\nBatch 410: torch.Size([2, 9]), torch.Size([2])\nBatch 411: torch.Size([2, 9]), torch.Size([2])\nBatch 412: torch.Size([2, 9]), torch.Size([2])\nBatch 413: torch.Size([2, 9]), torch.Size([2])\nBatch 414: torch.Size([2, 9]), torch.Size([2])\nBatch 415: torch.Size([2, 9]), torch.Size([2])\nBatch 416: torch.Size([2, 9]), torch.Size([2])\nBatch 417: torch.Size([2, 9]), torch.Size([2])\nBatch 418: torch.Size([2, 9]), torch.Size([2])\nBatch 419: torch.Size([2, 9]), torch.Size([2])\nBatch 420: torch.Size([2, 9]), torch.Size([2])\nBatch 421: torch.Size([2, 9]), torch.Size([2])\nBatch 422: torch.Size([2, 9]), torch.Size([2])\nBatch 423: torch.Size([2, 9]), torch.Size([2])\nBatch 424: torch.Size([2, 9]), torch.Size([2])\nBatch 425: torch.Size([2, 9]), torch.Size([2])\nBatch 426: torch.Size([2, 9]), torch.Size([2])\nBatch 427: torch.Size([2, 9]), torch.Size([2])\nBatch 428: torch.Size([2, 9]), torch.Size([2])\nBatch 429: torch.Size([2, 9]), torch.Size([2])\nBatch 430: torch.Size([2, 9]), torch.Size([2])\nBatch 431: torch.Size([2, 9]), torch.Size([2])\nBatch 432: torch.Size([2, 9]), torch.Size([2])\nBatch 433: torch.Size([2, 9]), torch.Size([2])\nBatch 434: torch.Size([2, 9]), torch.Size([2])\nBatch 435: torch.Size([2, 9]), torch.Size([2])\nBatch 436: torch.Size([2, 9]), torch.Size([2])\nBatch 437: torch.Size([2, 9]), torch.Size([2])\nBatch 438: torch.Size([2, 9]), torch.Size([2])\nBatch 439: torch.Size([2, 9]), torch.Size([2])\nBatch 440: torch.Size([2, 9]), torch.Size([2])\nBatch 441: torch.Size([2, 9]), torch.Size([2])\nBatch 442: torch.Size([2, 9]), torch.Size([2])\nBatch 443: torch.Size([2, 9]), torch.Size([2])\nBatch 444: torch.Size([2, 9]), torch.Size([2])\nBatch 445: torch.Size([2, 9]), torch.Size([2])\nBatch 446: torch.Size([2, 9]), torch.Size([2])\nBatch 447: torch.Size([2, 9]), torch.Size([2])\nBatch 448: torch.Size([2, 9]), torch.Size([2])\nBatch 449: torch.Size([2, 9]), torch.Size([2])\nBatch 450: torch.Size([2, 9]), torch.Size([2])\nBatch 451: torch.Size([2, 9]), torch.Size([2])\nBatch 452: torch.Size([2, 9]), torch.Size([2])\nBatch 453: torch.Size([2, 9]), torch.Size([2])\nBatch 454: torch.Size([2, 9]), torch.Size([2])\nBatch 455: torch.Size([2, 9]), torch.Size([2])\nBatch 456: torch.Size([2, 9]), torch.Size([2])\nBatch 457: torch.Size([2, 9]), torch.Size([2])\nBatch 458: torch.Size([2, 9]), torch.Size([2])\nBatch 459: torch.Size([2, 9]), torch.Size([2])\nBatch 460: torch.Size([2, 9]), torch.Size([2])\nBatch 461: torch.Size([2, 9]), torch.Size([2])\nBatch 462: torch.Size([2, 9]), torch.Size([2])\nBatch 463: torch.Size([2, 9]), torch.Size([2])\nBatch 464: torch.Size([2, 9]), torch.Size([2])\nBatch 465: torch.Size([2, 9]), torch.Size([2])\nBatch 466: torch.Size([2, 9]), torch.Size([2])\nBatch 467: torch.Size([2, 9]), torch.Size([2])\nBatch 468: torch.Size([2, 9]), torch.Size([2])\nBatch 469: torch.Size([2, 9]), torch.Size([2])\nBatch 470: torch.Size([2, 9]), torch.Size([2])\nBatch 471: torch.Size([2, 9]), torch.Size([2])\nBatch 472: torch.Size([2, 9]), torch.Size([2])\nBatch 473: torch.Size([2, 9]), torch.Size([2])\nBatch 474: torch.Size([2, 9]), torch.Size([2])\nBatch 475: torch.Size([2, 9]), torch.Size([2])\nBatch 476: torch.Size([2, 9]), torch.Size([2])\nBatch 477: torch.Size([2, 9]), torch.Size([2])\nBatch 478: torch.Size([2, 9]), torch.Size([2])\nBatch 479: torch.Size([2, 9]), torch.Size([2])\nBatch 480: torch.Size([2, 9]), torch.Size([2])\nBatch 481: torch.Size([2, 9]), torch.Size([2])\nBatch 482: torch.Size([2, 9]), torch.Size([2])\nBatch 483: torch.Size([2, 9]), torch.Size([2])\nBatch 484: torch.Size([2, 9]), torch.Size([2])\nBatch 485: torch.Size([2, 9]), torch.Size([2])\nBatch 486: torch.Size([2, 9]), torch.Size([2])\nBatch 487: torch.Size([2, 9]), torch.Size([2])\nBatch 488: torch.Size([2, 9]), torch.Size([2])\nBatch 489: torch.Size([2, 9]), torch.Size([2])\nBatch 490: torch.Size([2, 9]), torch.Size([2])\nBatch 491: torch.Size([2, 9]), torch.Size([2])\nBatch 492: torch.Size([2, 9]), torch.Size([2])\nBatch 493: torch.Size([2, 9]), torch.Size([2])\nBatch 494: torch.Size([2, 9]), torch.Size([2])\nBatch 495: torch.Size([2, 9]), torch.Size([2])\nBatch 496: torch.Size([2, 9]), torch.Size([2])\nBatch 497: torch.Size([2, 9]), torch.Size([2])\nBatch 498: torch.Size([2, 9]), torch.Size([2])\nBatch 499: torch.Size([2, 9]), torch.Size([2])\nBatch 500: torch.Size([2, 9]), torch.Size([2])\nBatch 501: torch.Size([2, 9]), torch.Size([2])\nBatch 502: torch.Size([2, 9]), torch.Size([2])\nBatch 503: torch.Size([2, 9]), torch.Size([2])\nBatch 504: torch.Size([2, 9]), torch.Size([2])\nBatch 505: torch.Size([2, 9]), torch.Size([2])\nBatch 506: torch.Size([2, 9]), torch.Size([2])\nBatch 507: torch.Size([2, 9]), torch.Size([2])\nBatch 508: torch.Size([2, 9]), torch.Size([2])\nBatch 509: torch.Size([2, 9]), torch.Size([2])\nBatch 510: torch.Size([2, 9]), torch.Size([2])\nBatch 511: torch.Size([2, 9]), torch.Size([2])\nBatch 512: torch.Size([2, 9]), torch.Size([2])\nBatch 513: torch.Size([2, 9]), torch.Size([2])\nBatch 514: torch.Size([2, 9]), torch.Size([2])\nBatch 515: torch.Size([2, 9]), torch.Size([2])\nBatch 516: torch.Size([2, 9]), torch.Size([2])\nBatch 517: torch.Size([2, 9]), torch.Size([2])\nBatch 518: torch.Size([2, 9]), torch.Size([2])\nBatch 519: torch.Size([2, 9]), torch.Size([2])\nBatch 520: torch.Size([2, 9]), torch.Size([2])\nBatch 521: torch.Size([2, 9]), torch.Size([2])\nBatch 522: torch.Size([2, 9]), torch.Size([2])\nBatch 523: torch.Size([2, 9]), torch.Size([2])\nBatch 524: torch.Size([2, 9]), torch.Size([2])\nBatch 525: torch.Size([2, 9]), torch.Size([2])\nBatch 526: torch.Size([2, 9]), torch.Size([2])\nBatch 527: torch.Size([2, 9]), torch.Size([2])\nBatch 528: torch.Size([2, 9]), torch.Size([2])\nBatch 529: torch.Size([2, 9]), torch.Size([2])\nBatch 530: torch.Size([2, 9]), torch.Size([2])\nBatch 531: torch.Size([2, 9]), torch.Size([2])\nBatch 532: torch.Size([2, 9]), torch.Size([2])\nBatch 533: torch.Size([2, 9]), torch.Size([2])\nBatch 534: torch.Size([2, 9]), torch.Size([2])\nBatch 535: torch.Size([2, 9]), torch.Size([2])\nBatch 536: torch.Size([2, 9]), torch.Size([2])\nBatch 537: torch.Size([2, 9]), torch.Size([2])\nBatch 538: torch.Size([2, 9]), torch.Size([2])\nBatch 539: torch.Size([2, 9]), torch.Size([2])\nBatch 540: torch.Size([2, 9]), torch.Size([2])\nBatch 541: torch.Size([2, 9]), torch.Size([2])\nBatch 542: torch.Size([2, 9]), torch.Size([2])\nBatch 543: torch.Size([2, 9]), torch.Size([2])\nBatch 544: torch.Size([2, 9]), torch.Size([2])\nBatch 545: torch.Size([2, 9]), torch.Size([2])\nBatch 546: torch.Size([2, 9]), torch.Size([2])\nBatch 547: torch.Size([2, 9]), torch.Size([2])\nBatch 548: torch.Size([2, 9]), torch.Size([2])\nBatch 549: torch.Size([2, 9]), torch.Size([2])\nBatch 550: torch.Size([2, 9]), torch.Size([2])\nBatch 551: torch.Size([2, 9]), torch.Size([2])\nBatch 552: torch.Size([2, 9]), torch.Size([2])\nBatch 553: torch.Size([2, 9]), torch.Size([2])\nBatch 554: torch.Size([2, 9]), torch.Size([2])\nBatch 555: torch.Size([2, 9]), torch.Size([2])\nBatch 556: torch.Size([2, 9]), torch.Size([2])\nBatch 557: torch.Size([2, 9]), torch.Size([2])\nBatch 558: torch.Size([2, 9]), torch.Size([2])\nBatch 559: torch.Size([2, 9]), torch.Size([2])\nBatch 560: torch.Size([2, 9]), torch.Size([2])\nBatch 561: torch.Size([2, 9]), torch.Size([2])\nBatch 562: torch.Size([2, 9]), torch.Size([2])\nBatch 563: torch.Size([2, 9]), torch.Size([2])\nBatch 564: torch.Size([2, 9]), torch.Size([2])\nBatch 565: torch.Size([2, 9]), torch.Size([2])\nBatch 566: torch.Size([2, 9]), torch.Size([2])\nBatch 567: torch.Size([2, 9]), torch.Size([2])\nBatch 568: torch.Size([2, 9]), torch.Size([2])\nBatch 569: torch.Size([2, 9]), torch.Size([2])\nBatch 570: torch.Size([2, 9]), torch.Size([2])\nBatch 571: torch.Size([2, 9]), torch.Size([2])\nBatch 572: torch.Size([2, 9]), torch.Size([2])\nBatch 573: torch.Size([2, 9]), torch.Size([2])\nBatch 574: torch.Size([2, 9]), torch.Size([2])\nBatch 575: torch.Size([2, 9]), torch.Size([2])\nBatch 576: torch.Size([2, 9]), torch.Size([2])\nBatch 577: torch.Size([2, 9]), torch.Size([2])\nBatch 578: torch.Size([2, 9]), torch.Size([2])\nBatch 579: torch.Size([2, 9]), torch.Size([2])\nBatch 580: torch.Size([2, 9]), torch.Size([2])\nBatch 581: torch.Size([2, 9]), torch.Size([2])\nBatch 582: torch.Size([2, 9]), torch.Size([2])\nBatch 583: torch.Size([2, 9]), torch.Size([2])\nBatch 584: torch.Size([2, 9]), torch.Size([2])\nBatch 585: torch.Size([2, 9]), torch.Size([2])\nBatch 586: torch.Size([2, 9]), torch.Size([2])\nBatch 587: torch.Size([2, 9]), torch.Size([2])\nBatch 588: torch.Size([2, 9]), torch.Size([2])\nBatch 589: torch.Size([2, 9]), torch.Size([2])\nBatch 590: torch.Size([2, 9]), torch.Size([2])\nBatch 591: torch.Size([2, 9]), torch.Size([2])\nBatch 592: torch.Size([2, 9]), torch.Size([2])\nBatch 593: torch.Size([2, 9]), torch.Size([2])\nBatch 594: torch.Size([2, 9]), torch.Size([2])\nBatch 595: torch.Size([2, 9]), torch.Size([2])\nBatch 596: torch.Size([2, 9]), torch.Size([2])\nBatch 597: torch.Size([2, 9]), torch.Size([2])\nBatch 598: torch.Size([2, 9]), torch.Size([2])\nBatch 599: torch.Size([2, 9]), torch.Size([2])\nBatch 600: torch.Size([2, 9]), torch.Size([2])\nBatch 601: torch.Size([2, 9]), torch.Size([2])\nBatch 602: torch.Size([2, 9]), torch.Size([2])\nBatch 603: torch.Size([2, 9]), torch.Size([2])\nBatch 604: torch.Size([2, 9]), torch.Size([2])\nBatch 605: torch.Size([2, 9]), torch.Size([2])\nBatch 606: torch.Size([2, 9]), torch.Size([2])\nBatch 607: torch.Size([2, 9]), torch.Size([2])\nBatch 608: torch.Size([2, 9]), torch.Size([2])\nBatch 609: torch.Size([2, 9]), torch.Size([2])\nBatch 610: torch.Size([2, 9]), torch.Size([2])\nBatch 611: torch.Size([2, 9]), torch.Size([2])\nBatch 612: torch.Size([2, 9]), torch.Size([2])\nBatch 613: torch.Size([2, 9]), torch.Size([2])\nBatch 614: torch.Size([2, 9]), torch.Size([2])\nBatch 615: torch.Size([2, 9]), torch.Size([2])\nBatch 616: torch.Size([2, 9]), torch.Size([2])\nBatch 617: torch.Size([2, 9]), torch.Size([2])\nBatch 618: torch.Size([2, 9]), torch.Size([2])\nBatch 619: torch.Size([2, 9]), torch.Size([2])\nBatch 620: torch.Size([2, 9]), torch.Size([2])\nBatch 621: torch.Size([2, 9]), torch.Size([2])\nBatch 622: torch.Size([2, 9]), torch.Size([2])\nBatch 623: torch.Size([2, 9]), torch.Size([2])\nBatch 624: torch.Size([2, 9]), torch.Size([2])\nBatch 625: torch.Size([2, 9]), torch.Size([2])\nBatch 626: torch.Size([2, 9]), torch.Size([2])\nBatch 627: torch.Size([2, 9]), torch.Size([2])\nBatch 628: torch.Size([2, 9]), torch.Size([2])\nBatch 629: torch.Size([2, 9]), torch.Size([2])\nBatch 630: torch.Size([2, 9]), torch.Size([2])\nBatch 631: torch.Size([2, 9]), torch.Size([2])\nBatch 632: torch.Size([2, 9]), torch.Size([2])\nBatch 633: torch.Size([2, 9]), torch.Size([2])\nBatch 634: torch.Size([2, 9]), torch.Size([2])\nBatch 635: torch.Size([2, 9]), torch.Size([2])\nBatch 636: torch.Size([2, 9]), torch.Size([2])\nBatch 637: torch.Size([2, 9]), torch.Size([2])\nBatch 638: torch.Size([2, 9]), torch.Size([2])\nBatch 639: torch.Size([2, 9]), torch.Size([2])\nBatch 640: torch.Size([2, 9]), torch.Size([2])\nBatch 641: torch.Size([2, 9]), torch.Size([2])\nBatch 642: torch.Size([2, 9]), torch.Size([2])\nBatch 643: torch.Size([2, 9]), torch.Size([2])\nBatch 644: torch.Size([2, 9]), torch.Size([2])\nBatch 645: torch.Size([2, 9]), torch.Size([2])\nBatch 646: torch.Size([2, 9]), torch.Size([2])\nBatch 647: torch.Size([2, 9]), torch.Size([2])\nBatch 648: torch.Size([2, 9]), torch.Size([2])\nBatch 649: torch.Size([2, 9]), torch.Size([2])\nBatch 650: torch.Size([2, 9]), torch.Size([2])\nBatch 651: torch.Size([2, 9]), torch.Size([2])\nBatch 652: torch.Size([2, 9]), torch.Size([2])\nBatch 653: torch.Size([2, 9]), torch.Size([2])\nBatch 654: torch.Size([2, 9]), torch.Size([2])\nBatch 655: torch.Size([2, 9]), torch.Size([2])\nBatch 656: torch.Size([2, 9]), torch.Size([2])\nBatch 657: torch.Size([2, 9]), torch.Size([2])\nBatch 658: torch.Size([2, 9]), torch.Size([2])\nBatch 659: torch.Size([2, 9]), torch.Size([2])\nBatch 660: torch.Size([2, 9]), torch.Size([2])\nBatch 661: torch.Size([2, 9]), torch.Size([2])\nBatch 662: torch.Size([2, 9]), torch.Size([2])\nBatch 663: torch.Size([2, 9]), torch.Size([2])\nBatch 664: torch.Size([2, 9]), torch.Size([2])\nBatch 665: torch.Size([2, 9]), torch.Size([2])\nBatch 666: torch.Size([2, 9]), torch.Size([2])\nBatch 667: torch.Size([2, 9]), torch.Size([2])\nBatch 668: torch.Size([2, 9]), torch.Size([2])\nBatch 669: torch.Size([2, 9]), torch.Size([2])\nBatch 670: torch.Size([2, 9]), torch.Size([2])\nBatch 671: torch.Size([2, 9]), torch.Size([2])\nBatch 672: torch.Size([2, 9]), torch.Size([2])\nBatch 673: torch.Size([2, 9]), torch.Size([2])\nBatch 674: torch.Size([2, 9]), torch.Size([2])\nBatch 675: torch.Size([2, 9]), torch.Size([2])\nBatch 676: torch.Size([2, 9]), torch.Size([2])\nBatch 677: torch.Size([2, 9]), torch.Size([2])\nBatch 678: torch.Size([2, 9]), torch.Size([2])\nBatch 679: torch.Size([2, 9]), torch.Size([2])\nBatch 680: torch.Size([2, 9]), torch.Size([2])\nBatch 681: torch.Size([2, 9]), torch.Size([2])\nBatch 682: torch.Size([2, 9]), torch.Size([2])\nBatch 683: torch.Size([2, 9]), torch.Size([2])\nBatch 684: torch.Size([2, 9]), torch.Size([2])\nBatch 685: torch.Size([2, 9]), torch.Size([2])\nBatch 686: torch.Size([2, 9]), torch.Size([2])\nBatch 687: torch.Size([2, 9]), torch.Size([2])\nBatch 688: torch.Size([2, 9]), torch.Size([2])\nBatch 689: torch.Size([2, 9]), torch.Size([2])\nBatch 690: torch.Size([2, 9]), torch.Size([2])\nBatch 691: torch.Size([2, 9]), torch.Size([2])\nBatch 692: torch.Size([2, 9]), torch.Size([2])\nBatch 693: torch.Size([2, 9]), torch.Size([2])\nBatch 694: torch.Size([2, 9]), torch.Size([2])\nBatch 695: torch.Size([2, 9]), torch.Size([2])\nBatch 696: torch.Size([2, 9]), torch.Size([2])\nBatch 697: torch.Size([2, 9]), torch.Size([2])\nBatch 698: torch.Size([2, 9]), torch.Size([2])\nBatch 699: torch.Size([2, 9]), torch.Size([2])\nBatch 700: torch.Size([2, 9]), torch.Size([2])\nBatch 701: torch.Size([2, 9]), torch.Size([2])\nBatch 702: torch.Size([2, 9]), torch.Size([2])\nBatch 703: torch.Size([2, 9]), torch.Size([2])\nBatch 704: torch.Size([2, 9]), torch.Size([2])\nBatch 705: torch.Size([2, 9]), torch.Size([2])\nBatch 706: torch.Size([2, 9]), torch.Size([2])\nBatch 707: torch.Size([2, 9]), torch.Size([2])\nBatch 708: torch.Size([2, 9]), torch.Size([2])\nBatch 709: torch.Size([2, 9]), torch.Size([2])\nBatch 710: torch.Size([2, 9]), torch.Size([2])\nBatch 711: torch.Size([2, 9]), torch.Size([2])\nBatch 712: torch.Size([2, 9]), torch.Size([2])\nBatch 713: torch.Size([2, 9]), torch.Size([2])\nBatch 714: torch.Size([2, 9]), torch.Size([2])\nBatch 715: torch.Size([2, 9]), torch.Size([2])\nBatch 716: torch.Size([2, 9]), torch.Size([2])\nBatch 717: torch.Size([2, 9]), torch.Size([2])\nBatch 718: torch.Size([2, 9]), torch.Size([2])\nBatch 719: torch.Size([2, 9]), torch.Size([2])\nBatch 720: torch.Size([2, 9]), torch.Size([2])\nBatch 721: torch.Size([2, 9]), torch.Size([2])\nBatch 722: torch.Size([2, 9]), torch.Size([2])\nBatch 723: torch.Size([2, 9]), torch.Size([2])\nBatch 724: torch.Size([2, 9]), torch.Size([2])\nBatch 725: torch.Size([2, 9]), torch.Size([2])\nBatch 726: torch.Size([2, 9]), torch.Size([2])\nBatch 727: torch.Size([2, 9]), torch.Size([2])\nBatch 728: torch.Size([2, 9]), torch.Size([2])\nBatch 729: torch.Size([2, 9]), torch.Size([2])\nBatch 730: torch.Size([2, 9]), torch.Size([2])\nBatch 731: torch.Size([2, 9]), torch.Size([2])\nBatch 732: torch.Size([2, 9]), torch.Size([2])\nBatch 733: torch.Size([2, 9]), torch.Size([2])\nBatch 734: torch.Size([2, 9]), torch.Size([2])\nBatch 735: torch.Size([2, 9]), torch.Size([2])\nBatch 736: torch.Size([2, 9]), torch.Size([2])\nBatch 737: torch.Size([2, 9]), torch.Size([2])\nBatch 738: torch.Size([2, 9]), torch.Size([2])\nBatch 739: torch.Size([2, 9]), torch.Size([2])\nBatch 740: torch.Size([2, 9]), torch.Size([2])\nBatch 741: torch.Size([2, 9]), torch.Size([2])\nBatch 742: torch.Size([2, 9]), torch.Size([2])\nBatch 743: torch.Size([2, 9]), torch.Size([2])\nBatch 744: torch.Size([2, 9]), torch.Size([2])\nBatch 745: torch.Size([2, 9]), torch.Size([2])\nBatch 746: torch.Size([2, 9]), torch.Size([2])\nBatch 747: torch.Size([2, 9]), torch.Size([2])\nBatch 748: torch.Size([2, 9]), torch.Size([2])\nBatch 749: torch.Size([2, 9]), torch.Size([2])\nBatch 750: torch.Size([2, 9]), torch.Size([2])\nBatch 751: torch.Size([2, 9]), torch.Size([2])\nBatch 752: torch.Size([2, 9]), torch.Size([2])\nBatch 753: torch.Size([2, 9]), torch.Size([2])\nBatch 754: torch.Size([2, 9]), torch.Size([2])\nBatch 755: torch.Size([2, 9]), torch.Size([2])\nBatch 756: torch.Size([2, 9]), torch.Size([2])\nBatch 757: torch.Size([2, 9]), torch.Size([2])\nBatch 758: torch.Size([2, 9]), torch.Size([2])\nBatch 759: torch.Size([2, 9]), torch.Size([2])\nBatch 760: torch.Size([2, 9]), torch.Size([2])\nBatch 761: torch.Size([2, 9]), torch.Size([2])\nBatch 762: torch.Size([2, 9]), torch.Size([2])\nBatch 763: torch.Size([2, 9]), torch.Size([2])\nBatch 764: torch.Size([2, 9]), torch.Size([2])\nBatch 765: torch.Size([2, 9]), torch.Size([2])\nBatch 766: torch.Size([2, 9]), torch.Size([2])\nBatch 767: torch.Size([2, 9]), torch.Size([2])\nBatch 768: torch.Size([2, 9]), torch.Size([2])\nBatch 769: torch.Size([2, 9]), torch.Size([2])\nBatch 770: torch.Size([2, 9]), torch.Size([2])\nBatch 771: torch.Size([2, 9]), torch.Size([2])\nBatch 772: torch.Size([2, 9]), torch.Size([2])\nBatch 773: torch.Size([2, 9]), torch.Size([2])\nBatch 774: torch.Size([2, 9]), torch.Size([2])\nBatch 775: torch.Size([2, 9]), torch.Size([2])\nBatch 776: torch.Size([2, 9]), torch.Size([2])\nBatch 777: torch.Size([2, 9]), torch.Size([2])\nBatch 778: torch.Size([2, 9]), torch.Size([2])\nBatch 779: torch.Size([2, 9]), torch.Size([2])\nBatch 780: torch.Size([2, 9]), torch.Size([2])\nBatch 781: torch.Size([2, 9]), torch.Size([2])\nBatch 782: torch.Size([2, 9]), torch.Size([2])\nBatch 783: torch.Size([2, 9]), torch.Size([2])\nBatch 784: torch.Size([2, 9]), torch.Size([2])\nBatch 785: torch.Size([2, 9]), torch.Size([2])\nBatch 786: torch.Size([2, 9]), torch.Size([2])\nBatch 787: torch.Size([2, 9]), torch.Size([2])\nBatch 788: torch.Size([2, 9]), torch.Size([2])\nBatch 789: torch.Size([2, 9]), torch.Size([2])\nBatch 790: torch.Size([2, 9]), torch.Size([2])\nBatch 791: torch.Size([2, 9]), torch.Size([2])\nBatch 792: torch.Size([2, 9]), torch.Size([2])\nBatch 793: torch.Size([2, 9]), torch.Size([2])\nBatch 794: torch.Size([2, 9]), torch.Size([2])\nBatch 795: torch.Size([2, 9]), torch.Size([2])\nBatch 796: torch.Size([2, 9]), torch.Size([2])\nBatch 797: torch.Size([2, 9]), torch.Size([2])\nBatch 798: torch.Size([2, 9]), torch.Size([2])\nBatch 799: torch.Size([2, 9]), torch.Size([2])\nBatch 800: torch.Size([2, 9]), torch.Size([2])\nBatch 801: torch.Size([2, 9]), torch.Size([2])\nBatch 802: torch.Size([2, 9]), torch.Size([2])\nBatch 803: torch.Size([2, 9]), torch.Size([2])\nBatch 804: torch.Size([2, 9]), torch.Size([2])\nBatch 805: torch.Size([2, 9]), torch.Size([2])\nBatch 806: torch.Size([2, 9]), torch.Size([2])\nBatch 807: torch.Size([2, 9]), torch.Size([2])\nBatch 808: torch.Size([2, 9]), torch.Size([2])\nBatch 809: torch.Size([2, 9]), torch.Size([2])\nBatch 810: torch.Size([2, 9]), torch.Size([2])\nBatch 811: torch.Size([2, 9]), torch.Size([2])\nBatch 812: torch.Size([2, 9]), torch.Size([2])\nBatch 813: torch.Size([2, 9]), torch.Size([2])\nBatch 814: torch.Size([2, 9]), torch.Size([2])\nBatch 815: torch.Size([2, 9]), torch.Size([2])\nBatch 816: torch.Size([2, 9]), torch.Size([2])\nBatch 817: torch.Size([2, 9]), torch.Size([2])\nBatch 818: torch.Size([2, 9]), torch.Size([2])\nBatch 819: torch.Size([2, 9]), torch.Size([2])\nBatch 820: torch.Size([2, 9]), torch.Size([2])\nBatch 821: torch.Size([2, 9]), torch.Size([2])\nBatch 822: torch.Size([2, 9]), torch.Size([2])\nBatch 823: torch.Size([2, 9]), torch.Size([2])\nBatch 824: torch.Size([2, 9]), torch.Size([2])\nBatch 825: torch.Size([2, 9]), torch.Size([2])\nBatch 826: torch.Size([2, 9]), torch.Size([2])\nBatch 827: torch.Size([2, 9]), torch.Size([2])\nBatch 828: torch.Size([2, 9]), torch.Size([2])\nBatch 829: torch.Size([2, 9]), torch.Size([2])\nBatch 830: torch.Size([2, 9]), torch.Size([2])\nBatch 831: torch.Size([2, 9]), torch.Size([2])\nBatch 832: torch.Size([2, 9]), torch.Size([2])\nBatch 833: torch.Size([2, 9]), torch.Size([2])\nBatch 834: torch.Size([2, 9]), torch.Size([2])\nBatch 835: torch.Size([2, 9]), torch.Size([2])\nBatch 836: torch.Size([2, 9]), torch.Size([2])\nBatch 837: torch.Size([2, 9]), torch.Size([2])\nBatch 838: torch.Size([2, 9]), torch.Size([2])\nBatch 839: torch.Size([2, 9]), torch.Size([2])\nBatch 840: torch.Size([2, 9]), torch.Size([2])\nBatch 841: torch.Size([2, 9]), torch.Size([2])\nBatch 842: torch.Size([2, 9]), torch.Size([2])\nBatch 843: torch.Size([2, 9]), torch.Size([2])\nBatch 844: torch.Size([2, 9]), torch.Size([2])\nBatch 845: torch.Size([2, 9]), torch.Size([2])\nBatch 846: torch.Size([2, 9]), torch.Size([2])\nBatch 847: torch.Size([2, 9]), torch.Size([2])\nBatch 848: torch.Size([2, 9]), torch.Size([2])\nBatch 849: torch.Size([2, 9]), torch.Size([2])\nBatch 850: torch.Size([2, 9]), torch.Size([2])\nBatch 851: torch.Size([2, 9]), torch.Size([2])\nBatch 852: torch.Size([2, 9]), torch.Size([2])\nBatch 853: torch.Size([2, 9]), torch.Size([2])\nBatch 854: torch.Size([2, 9]), torch.Size([2])\nBatch 855: torch.Size([2, 9]), torch.Size([2])\nBatch 856: torch.Size([2, 9]), torch.Size([2])\nBatch 857: torch.Size([2, 9]), torch.Size([2])\nBatch 858: torch.Size([2, 9]), torch.Size([2])\nBatch 859: torch.Size([2, 9]), torch.Size([2])\nBatch 860: torch.Size([2, 9]), torch.Size([2])\nBatch 861: torch.Size([2, 9]), torch.Size([2])\nBatch 862: torch.Size([2, 9]), torch.Size([2])\nBatch 863: torch.Size([2, 9]), torch.Size([2])\nBatch 864: torch.Size([2, 9]), torch.Size([2])\nBatch 865: torch.Size([2, 9]), torch.Size([2])\nBatch 866: torch.Size([2, 9]), torch.Size([2])\nBatch 867: torch.Size([2, 9]), torch.Size([2])\nBatch 868: torch.Size([2, 9]), torch.Size([2])\nBatch 869: torch.Size([2, 9]), torch.Size([2])\nBatch 870: torch.Size([2, 9]), torch.Size([2])\nBatch 871: torch.Size([2, 9]), torch.Size([2])\nBatch 872: torch.Size([2, 9]), torch.Size([2])\nBatch 873: torch.Size([2, 9]), torch.Size([2])\nBatch 874: torch.Size([2, 9]), torch.Size([2])\nBatch 875: torch.Size([2, 9]), torch.Size([2])\nBatch 876: torch.Size([2, 9]), torch.Size([2])\nBatch 877: torch.Size([2, 9]), torch.Size([2])\nBatch 878: torch.Size([2, 9]), torch.Size([2])\nBatch 879: torch.Size([2, 9]), torch.Size([2])\nBatch 880: torch.Size([2, 9]), torch.Size([2])\nBatch 881: torch.Size([2, 9]), torch.Size([2])\nBatch 882: torch.Size([2, 9]), torch.Size([2])\nBatch 883: torch.Size([2, 9]), torch.Size([2])\nBatch 884: torch.Size([2, 9]), torch.Size([2])\nBatch 885: torch.Size([2, 9]), torch.Size([2])\nBatch 886: torch.Size([2, 9]), torch.Size([2])\nBatch 887: torch.Size([2, 9]), torch.Size([2])\nBatch 888: torch.Size([2, 9]), torch.Size([2])\nBatch 889: torch.Size([2, 9]), torch.Size([2])\nBatch 890: torch.Size([2, 9]), torch.Size([2])\nBatch 891: torch.Size([2, 9]), torch.Size([2])\nBatch 892: torch.Size([2, 9]), torch.Size([2])\nBatch 893: torch.Size([2, 9]), torch.Size([2])\nBatch 894: torch.Size([2, 9]), torch.Size([2])\nBatch 895: torch.Size([2, 9]), torch.Size([2])\nBatch 896: torch.Size([2, 9]), torch.Size([2])\nBatch 897: torch.Size([2, 9]), torch.Size([2])\nBatch 898: torch.Size([2, 9]), torch.Size([2])\nBatch 899: torch.Size([2, 9]), torch.Size([2])\nBatch 900: torch.Size([2, 9]), torch.Size([2])\nBatch 901: torch.Size([2, 9]), torch.Size([2])\nBatch 902: torch.Size([2, 9]), torch.Size([2])\nBatch 903: torch.Size([2, 9]), torch.Size([2])\nBatch 904: torch.Size([2, 9]), torch.Size([2])\nBatch 905: torch.Size([2, 9]), torch.Size([2])\nBatch 906: torch.Size([2, 9]), torch.Size([2])\nBatch 907: torch.Size([2, 9]), torch.Size([2])\nBatch 908: torch.Size([2, 9]), torch.Size([2])\nBatch 909: torch.Size([2, 9]), torch.Size([2])\nBatch 910: torch.Size([2, 9]), torch.Size([2])\nBatch 911: torch.Size([2, 9]), torch.Size([2])\nBatch 912: torch.Size([2, 9]), torch.Size([2])\nBatch 913: torch.Size([2, 9]), torch.Size([2])\nBatch 914: torch.Size([2, 9]), torch.Size([2])\nBatch 915: torch.Size([2, 9]), torch.Size([2])\nBatch 916: torch.Size([2, 9]), torch.Size([2])\nBatch 917: torch.Size([2, 9]), torch.Size([2])\nBatch 918: torch.Size([2, 9]), torch.Size([2])\nBatch 919: torch.Size([2, 9]), torch.Size([2])\nBatch 920: torch.Size([2, 9]), torch.Size([2])\nBatch 921: torch.Size([2, 9]), torch.Size([2])\nBatch 922: torch.Size([2, 9]), torch.Size([2])\nBatch 923: torch.Size([2, 9]), torch.Size([2])\nBatch 924: torch.Size([2, 9]), torch.Size([2])\nBatch 925: torch.Size([2, 9]), torch.Size([2])\nBatch 926: torch.Size([2, 9]), torch.Size([2])\nBatch 927: torch.Size([2, 9]), torch.Size([2])\nBatch 928: torch.Size([2, 9]), torch.Size([2])\nBatch 929: torch.Size([2, 9]), torch.Size([2])\nBatch 930: torch.Size([2, 9]), torch.Size([2])\nBatch 931: torch.Size([2, 9]), torch.Size([2])\nBatch 932: torch.Size([2, 9]), torch.Size([2])\nBatch 933: torch.Size([2, 9]), torch.Size([2])\nBatch 934: torch.Size([2, 9]), torch.Size([2])\nBatch 935: torch.Size([2, 9]), torch.Size([2])\nBatch 936: torch.Size([2, 9]), torch.Size([2])\nBatch 937: torch.Size([2, 9]), torch.Size([2])\nBatch 938: torch.Size([2, 9]), torch.Size([2])\nBatch 939: torch.Size([2, 9]), torch.Size([2])\nBatch 940: torch.Size([2, 9]), torch.Size([2])\nBatch 941: torch.Size([2, 9]), torch.Size([2])\nBatch 942: torch.Size([2, 9]), torch.Size([2])\nBatch 943: torch.Size([2, 9]), torch.Size([2])\nBatch 944: torch.Size([2, 9]), torch.Size([2])\nBatch 945: torch.Size([2, 9]), torch.Size([2])\nBatch 946: torch.Size([2, 9]), torch.Size([2])\nBatch 947: torch.Size([2, 9]), torch.Size([2])\nBatch 948: torch.Size([2, 9]), torch.Size([2])\nBatch 949: torch.Size([2, 9]), torch.Size([2])\nBatch 950: torch.Size([2, 9]), torch.Size([2])\nBatch 951: torch.Size([2, 9]), torch.Size([2])\nBatch 952: torch.Size([2, 9]), torch.Size([2])\nBatch 953: torch.Size([2, 9]), torch.Size([2])\nBatch 954: torch.Size([2, 9]), torch.Size([2])\nBatch 955: torch.Size([2, 9]), torch.Size([2])\nBatch 956: torch.Size([2, 9]), torch.Size([2])\nBatch 957: torch.Size([2, 9]), torch.Size([2])\nBatch 958: torch.Size([2, 9]), torch.Size([2])\nBatch 959: torch.Size([2, 9]), torch.Size([2])\nBatch 960: torch.Size([2, 9]), torch.Size([2])\nBatch 961: torch.Size([2, 9]), torch.Size([2])\nBatch 962: torch.Size([2, 9]), torch.Size([2])\nBatch 963: torch.Size([2, 9]), torch.Size([2])\nBatch 964: torch.Size([2, 9]), torch.Size([2])\nBatch 965: torch.Size([2, 9]), torch.Size([2])\nBatch 966: torch.Size([2, 9]), torch.Size([2])\nBatch 967: torch.Size([2, 9]), torch.Size([2])\nBatch 968: torch.Size([2, 9]), torch.Size([2])\nBatch 969: torch.Size([2, 9]), torch.Size([2])\nBatch 970: torch.Size([2, 9]), torch.Size([2])\nBatch 971: torch.Size([2, 9]), torch.Size([2])\nBatch 972: torch.Size([2, 9]), torch.Size([2])\nBatch 973: torch.Size([2, 9]), torch.Size([2])\nBatch 974: torch.Size([2, 9]), torch.Size([2])\nBatch 975: torch.Size([2, 9]), torch.Size([2])\nBatch 976: torch.Size([2, 9]), torch.Size([2])\nBatch 977: torch.Size([2, 9]), torch.Size([2])\nBatch 978: torch.Size([2, 9]), torch.Size([2])\nBatch 979: torch.Size([2, 9]), torch.Size([2])\nBatch 980: torch.Size([2, 9]), torch.Size([2])\nBatch 981: torch.Size([2, 9]), torch.Size([2])\nBatch 982: torch.Size([2, 9]), torch.Size([2])\nBatch 983: torch.Size([2, 9]), torch.Size([2])\nBatch 984: torch.Size([2, 9]), torch.Size([2])\nBatch 985: torch.Size([2, 9]), torch.Size([2])\nBatch 986: torch.Size([2, 9]), torch.Size([2])\nBatch 987: torch.Size([2, 9]), torch.Size([2])\nBatch 988: torch.Size([2, 9]), torch.Size([2])\nBatch 989: torch.Size([2, 9]), torch.Size([2])\nBatch 990: torch.Size([2, 9]), torch.Size([2])\nBatch 991: torch.Size([2, 9]), torch.Size([2])\nBatch 992: torch.Size([2, 9]), torch.Size([2])\nBatch 993: torch.Size([2, 9]), torch.Size([2])\nBatch 994: torch.Size([2, 9]), torch.Size([2])\nBatch 995: torch.Size([2, 9]), torch.Size([2])\nBatch 996: torch.Size([2, 9]), torch.Size([2])\nBatch 997: torch.Size([2, 9]), torch.Size([2])\nBatch 998: torch.Size([2, 9]), torch.Size([2])\nBatch 999: torch.Size([2, 9]), torch.Size([2])\nBatch 1000: torch.Size([2, 9]), torch.Size([2])\nBatch 1001: torch.Size([2, 9]), torch.Size([2])\nBatch 1002: torch.Size([2, 9]), torch.Size([2])\nBatch 1003: torch.Size([2, 9]), torch.Size([2])\nBatch 1004: torch.Size([2, 9]), torch.Size([2])\nBatch 1005: torch.Size([1, 9]), torch.Size([1])\n"}]},{"source":"# Create a model using the nn.Sequential API\nmodel = nn.Sequential(nn.Linear(4, 16), nn.Linear(16, 1))","metadata":{"executionTime":0,"lastSuccessfullyExecutedCode":"# Create a model using the nn.Sequential API\nmodel = nn.Sequential(nn.Linear(4, 16), nn.Linear(16, 1))"},"cell_type":"code","id":"301c252f-a57d-4bbf-8b4a-398e93346976","execution_count":26,"outputs":[]},{"source":"### 3. Define the loss function","metadata":{},"cell_type":"markdown","id":"910eac02-bbe6-4537-b02b-0688ed683572"},{"source":"The cross entropy loss is the most used loss for classification problems. ","metadata":{},"cell_type":"markdown","id":"3e90f8c2-0a99-41d9-bea7-39f3ec37a2b7"},{"source":"import torch.nn.functional as F\n\ny = [2]\nscores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n\n# Create a one-hot encoded vector of the label y\none_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n\n# Create the cross entropy loss function\nloss = nn.CrossEntropyLoss()\n\n# Calculate the cross entropy loss\nloss(scores.double(), one_hot_label.double())","metadata":{"executionTime":28,"lastSuccessfullyExecutedCode":"import torch.nn.functional as F\n\ny = [2]\nscores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n\n# Create a one-hot encoded vector of the label y\none_hot_label = F.one_hot(torch.tensor(y), scores.shape[1])\n\n# Create the cross entropy loss function\nloss = nn.CrossEntropyLoss()\n\n# Calculate the cross entropy loss\nloss(scores.double(), one_hot_label.double())"},"cell_type":"code","id":"e9ff70d7-2bce-43b5-bef5-45fda5b35e2b","execution_count":27,"outputs":[{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"tensor(8.0619, dtype=torch.float64)"},"metadata":{}}]},{"source":"Note: \nThis code is calculating the cross entropy loss for a single sample with four classes.\nFirst, it defines the ground truth label y as class 2. Then, it creates a tensor scores of shape (1, 4) with the predicted scores for each class.\nNext, it uses the F.one_hot function to create a one-hot encoded tensor of y with the same number of classes as scores. If the ground truth label y is class 2, it means that the correct class for the given sample is the one represented by the third element (index 2) of the scores tensor. The resulting one_hot_label tensor is of shape (1, 4) and has a 1 in the 2nd position (corresponding to the ground truth class) and 0s elsewhere.\nFinally, it creates an instance of the nn.CrossEntropyLoss() class and applies it to the scores tensor and the one_hot_label tensor using the .double() method to ensure that both tensors have the same data type (double precision).\nThe output of the loss function is a scalar tensor representing the cross entropy loss between the predicted scores and the one-hot encoded ground truth label.","metadata":{},"cell_type":"markdown","id":"8f3f6996-8ff2-47c4-b17f-e1c3572e0452"},{"source":"### 4. Set up an optimizer","metadata":{},"cell_type":"markdown","id":"04af44b9-82b0-41c2-ad39-cdffb39856ac"},{"source":"In PyTorch, an optimizer takes care of weight updates. The most common optimizer is stochastic gradient descent (SGD).","metadata":{},"cell_type":"markdown","id":"29cd77b4-51e2-45fc-8b0c-c2d5d00dfb3c"},{"source":"### Manual optimization","metadata":{},"cell_type":"markdown","id":"9ac51d9a-c363-47c9-896e-4fcacffdeb42"},{"source":"# Initialize the model and loss function\nmodel = nn.Sequential(nn.Linear(16, 8),\n                      nn.Linear(8, 4),\n                      nn.Linear(4, 2))\ncriterion = nn.CrossEntropyLoss()\n\n# Define the input data and target labels\ninputs = torch.randn(2, 16)\nlabels = torch.LongTensor([0, 1])\n\n# Compute the forward pass\noutputs = model(inputs)\n\n# Compute the loss\nloss = criterion(outputs, labels)\n\n# Compute the gradients using backpropagation\nloss.backward()\n\n# Learning rate is typically small\nlr = 0.001\n\n# Update the weights\nweight = model[0].weight\nweight_grad = model[0].weight.grad\nweight = weight - lr * weight_grad\n\n# Update the biases\nbias = model[0].bias\nbias_grad = model[0].bias.grad\nbias = bias - lr * bias_grad\n\nprint(weight, bias)","metadata":{"executionTime":32,"lastSuccessfullyExecutedCode":"# Initialize the model and loss function\nmodel = nn.Sequential(nn.Linear(16, 8),\n                      nn.Linear(8, 4),\n                      nn.Linear(4, 2))\ncriterion = nn.CrossEntropyLoss()\n\n# Define the input data and target labels\ninputs = torch.randn(2, 16)\nlabels = torch.LongTensor([0, 1])\n\n# Compute the forward pass\noutputs = model(inputs)\n\n# Compute the loss\nloss = criterion(outputs, labels)\n\n# Compute the gradients using backpropagation\nloss.backward()\n\n# Learning rate is typically small\nlr = 0.001\n\n# Update the weights\nweight = model[0].weight\nweight_grad = model[0].weight.grad\nweight = weight - lr * weight_grad\n\n# Update the biases\nbias = model[0].bias\nbias_grad = model[0].bias.grad\nbias = bias - lr * bias_grad\n\nprint(weight, bias)"},"cell_type":"code","id":"e4e1c4c6-5b35-47fe-b6be-9f8f57ab5d7a","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[-0.1046, -0.1825,  0.2345,  0.2039,  0.2050, -0.0929, -0.0348, -0.2279,\n         -0.0912,  0.1672, -0.2000,  0.1057, -0.0429,  0.1656,  0.2368,  0.1165],\n        [-0.1054,  0.0504,  0.2301,  0.1463, -0.0181,  0.1403, -0.1603,  0.0666,\n          0.2005, -0.0867, -0.1591, -0.0212, -0.1508, -0.1889, -0.0906, -0.1523],\n        [-0.1804, -0.0599, -0.0948,  0.2137, -0.0770, -0.1731,  0.1942,  0.1670,\n         -0.1727,  0.2469,  0.1497, -0.0099, -0.2312,  0.0446, -0.1156, -0.0287],\n        [ 0.1825,  0.0535, -0.2371, -0.0697, -0.1479,  0.0196,  0.1585, -0.0800,\n         -0.2424,  0.0997,  0.2322,  0.1556, -0.0753, -0.2328, -0.1764, -0.0793],\n        [ 0.0620,  0.1354,  0.1916,  0.0736, -0.0134, -0.2190,  0.1367, -0.0543,\n         -0.0534,  0.0748, -0.0093,  0.1957, -0.1132, -0.1577, -0.1728, -0.0767],\n        [ 0.1928,  0.0470, -0.0207,  0.0651,  0.1932, -0.1085,  0.0132, -0.0191,\n         -0.0323,  0.0374, -0.2084, -0.2297,  0.0679, -0.2338,  0.0061, -0.0486],\n        [-0.2357,  0.2027,  0.2478, -0.0652, -0.0228, -0.0605,  0.1970,  0.1104,\n         -0.0292, -0.1911, -0.2097,  0.1400, -0.1049, -0.0635,  0.2359,  0.0334],\n        [ 0.0507,  0.2351,  0.0774,  0.1596, -0.1321, -0.0891,  0.1931,  0.0155,\n         -0.1043,  0.0738, -0.0619, -0.0243,  0.1298,  0.0506,  0.1314, -0.1677]],\n       grad_fn=<SubBackward0>) tensor([-0.0627,  0.1639, -0.0754,  0.1646, -0.1750, -0.2118, -0.0785, -0.1440],\n       grad_fn=<SubBackward0>)\n"}]},{"source":"### Using the PyTorch optimize","metadata":{},"cell_type":"markdown","id":"cc2006ea-c3c0-4666-a7f2-5c43d302a8d0"},{"source":"import torch.optim as optim\n\n# Create the optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Update the model's parameters using the optimizer\noptimizer.step()\n\nprint(weight, bias)","metadata":{"executionTime":55,"lastSuccessfullyExecutedCode":"import torch.optim as optim\n\n# Create the optimizer\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\n# Update the model's parameters using the optimizer\noptimizer.step()\n\nprint(weight, bias)"},"cell_type":"code","id":"a5071d23-2153-4f65-a5c7-4ab9f4bd3548","execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":"tensor([[-0.1046, -0.1825,  0.2345,  0.2039,  0.2050, -0.0929, -0.0348, -0.2279,\n         -0.0912,  0.1672, -0.2000,  0.1057, -0.0429,  0.1656,  0.2368,  0.1165],\n        [-0.1054,  0.0504,  0.2301,  0.1463, -0.0181,  0.1403, -0.1603,  0.0666,\n          0.2005, -0.0867, -0.1591, -0.0212, -0.1508, -0.1889, -0.0906, -0.1523],\n        [-0.1804, -0.0599, -0.0948,  0.2137, -0.0770, -0.1731,  0.1942,  0.1670,\n         -0.1727,  0.2469,  0.1497, -0.0099, -0.2312,  0.0446, -0.1156, -0.0287],\n        [ 0.1825,  0.0535, -0.2371, -0.0697, -0.1479,  0.0196,  0.1585, -0.0800,\n         -0.2424,  0.0997,  0.2322,  0.1556, -0.0753, -0.2328, -0.1764, -0.0793],\n        [ 0.0620,  0.1354,  0.1916,  0.0736, -0.0134, -0.2190,  0.1367, -0.0543,\n         -0.0534,  0.0748, -0.0093,  0.1957, -0.1132, -0.1577, -0.1728, -0.0767],\n        [ 0.1928,  0.0470, -0.0207,  0.0651,  0.1932, -0.1085,  0.0132, -0.0191,\n         -0.0323,  0.0374, -0.2084, -0.2297,  0.0679, -0.2338,  0.0061, -0.0486],\n        [-0.2357,  0.2027,  0.2478, -0.0652, -0.0228, -0.0605,  0.1970,  0.1104,\n         -0.0292, -0.1911, -0.2097,  0.1400, -0.1049, -0.0635,  0.2359,  0.0334],\n        [ 0.0507,  0.2351,  0.0774,  0.1596, -0.1321, -0.0891,  0.1931,  0.0155,\n         -0.1043,  0.0738, -0.0619, -0.0243,  0.1298,  0.0506,  0.1314, -0.1677]],\n       grad_fn=<SubBackward0>) tensor([-0.0627,  0.1639, -0.0754,  0.1646, -0.1750, -0.2118, -0.0785, -0.1440],\n       grad_fn=<SubBackward0>)\n"}]},{"source":"Note: In the code above, the optimizer is an instance of the stochastic gradient descent (SGD) algorithm, which is a popular optimization algorithm used in deep learning. The learning rate (lr) is set to 0.001, which determines how much the optimizer should adjust the parameters based on the gradients of the loss function.\nAfter defining the optimizer, the step() method is called to update the model's parameters based on the gradients computed during backpropagation. This step is typically executed inside a training loop, where the model is iteratively trained on mini-batches of data.","metadata":{},"cell_type":"markdown","id":"b6e6fefd-971b-41ce-8a10-f912689fe662"},{"source":"### 5. Define a training loop ","metadata":{},"cell_type":"markdown","id":"b72636c6-9dd5-43f5-bb5f-d0c2f6068f93"},{"source":"# Create an instance of the MyDataset class and a DataLoader to load the data in batches.\ndataset = MyDataset('ds_salaries_clean.csv')\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n\n# Create the model\nmodel = nn.Sequential(nn.Linear(4, 2),nn.Sigmoid(),nn.Linear(2, 1))\n\n# Create the loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nnum_epochs = 10\n\n# Loop through the dataset multiple times\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        # Set the gradients to zero\n        optimizer.zero_grad()\n        # Get feature and target from the data loader\n        feature, target = data\n        # Run a forward pass\n        pred = model(feature)\n        # Compute loss and gradients\n        loss = criterion(pred, target)\n        loss.backward()\n        # Update the parameters\n        optimizer.step()\n\ndef show_results(model, dataloader):\n    \"\"\"\n    The show_results function takes a PyTorch model and a PyTorch DataLoader object as input and    prints the ground truth and predicted values for each batch in the DataLoader.\n\n    Parameters:\n            model: a PyTorch model object that takes in features as input and outputs predicted                     values.\n            dataloader: a PyTorch DataLoader object that contains the input features and target                     salaries in batches.\n    Returns:\n            None.\n    \"\"\"\n    with torch.no_grad():\n        for data in dataloader:\n            feature, target = data\n            pred = model(feature)\n            for i in range(len(feature)):\n                print(f\"Truth value: {target[i]:.3f}. Predicted value: {pred[i][0]:.3f}.\")\n                \nshow_results(model, dataloader)","metadata":{"executionTime":213,"lastSuccessfullyExecutedCode":"# Create an instance of the MyDataset class and a DataLoader to load the data in batches.\ndataset = MyDataset('ds_salaries_clean.csv')\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n\n# Create the model\nmodel = nn.Sequential(nn.Linear(4, 2),nn.Sigmoid(),nn.Linear(2, 1))\n\n# Create the loss and optimizer\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nnum_epochs = 10\n\n# Loop through the dataset multiple times\nfor epoch in range(num_epochs):\n    for data in dataloader:\n        # Set the gradients to zero\n        optimizer.zero_grad()\n        # Get feature and target from the data loader\n        feature, target = data\n        # Run a forward pass\n        pred = model(feature)\n        # Compute loss and gradients\n        loss = criterion(pred, target)\n        loss.backward()\n        # Update the parameters\n        optimizer.step()\n\ndef show_results(model, dataloader):\n    \"\"\"\n    The show_results function takes a PyTorch model and a PyTorch DataLoader object as input and    prints the ground truth and predicted values for each batch in the DataLoader.\n\n    Parameters:\n            model: a PyTorch model object that takes in features as input and outputs predicted                     values.\n            dataloader: a PyTorch DataLoader object that contains the input features and target                     salaries in batches.\n    Returns:\n            None.\n    \"\"\"\n    with torch.no_grad():\n        for data in dataloader:\n            feature, target = data\n            pred = model(feature)\n            for i in range(len(feature)):\n                print(f\"Truth value: {target[i]:.3f}. Predicted value: {pred[i][0]:.3f}.\")\n                \nshow_results(model, dataloader)"},"cell_type":"code","id":"f74dd190-18de-4b4a-9ad9-944911bb1c02","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"Truth value: 0.228. Predicted value: 0.188.\nTruth value: 0.175. Predicted value: 0.198.\nTruth value: 0.197. Predicted value: 0.197.\nTruth value: 0.116. Predicted value: 0.182.\nTruth value: 0.328. Predicted value: 0.183.\nTruth value: 0.167. Predicted value: 0.197.\nTruth value: 0.231. Predicted value: 0.188.\nTruth value: 0.217. Predicted value: 0.188.\nTruth value: 0.195. Predicted value: 0.202.\nTruth value: 0.188. Predicted value: 0.188.\nTruth value: 0.280. Predicted value: 0.204.\nTruth value: 0.100. Predicted value: 0.220.\nTruth value: 0.087. Predicted value: 0.211.\nTruth value: 0.100. Predicted value: 0.188.\nTruth value: 0.283. Predicted value: 0.195.\nTruth value: 0.750. Predicted value: 0.211.\nTruth value: 0.142. Predicted value: 0.192.\nTruth value: 0.250. Predicted value: 0.188.\nTruth value: 0.108. Predicted value: 0.191.\nTruth value: 0.300. Predicted value: 0.188.\nTruth value: 0.233. Predicted value: 0.188.\nTruth value: 0.175. Predicted value: 0.188.\nTruth value: 0.040. Predicted value: 0.188.\nTruth value: 0.067. Predicted value: 0.195.\nTruth value: 0.267. Predicted value: 0.197.\nTruth value: 0.095. Predicted value: 0.207.\nTruth value: 0.392. Predicted value: 0.177.\nTruth value: 0.225. Predicted value: 0.195.\nTruth value: 0.056. Predicted value: 0.204.\nTruth value: 0.116. Predicted value: 0.215.\nTruth value: 0.306. Predicted value: 0.186.\nTruth value: 0.090. Predicted value: 0.202.\nTruth value: 0.090. Predicted value: 0.201.\nTruth value: 0.099. Predicted value: 0.200.\nTruth value: 0.193. Predicted value: 0.201.\nTruth value: 0.160. Predicted value: 0.192.\nTruth value: 0.403. Predicted value: 0.180.\nTruth value: 0.130. Predicted value: 0.197.\nTruth value: 0.156. Predicted value: 0.188.\nTruth value: 0.138. Predicted value: 0.211.\nTruth value: 0.313. Predicted value: 0.186.\nTruth value: 0.295. Predicted value: 0.186.\nTruth value: 0.250. Predicted value: 0.186.\nTruth value: 0.205. Predicted value: 0.188.\nTruth value: 0.135. Predicted value: 0.216.\nTruth value: 0.173. Predicted value: 0.186.\nTruth value: 0.103. Predicted value: 0.192.\nTruth value: 0.149. Predicted value: 0.202.\nTruth value: 0.125. Predicted value: 0.211.\nTruth value: 0.233. Predicted value: 0.195.\nTruth value: 0.125. Predicted value: 0.208.\nTruth value: 0.256. Predicted value: 0.177.\nTruth value: 0.028. Predicted value: 0.200.\nTruth value: 0.099. Predicted value: 0.204.\nTruth value: 0.200. Predicted value: 0.200.\nTruth value: 0.290. Predicted value: 0.186.\nTruth value: 0.148. Predicted value: 0.197.\nTruth value: 0.083. Predicted value: 0.207.\nTruth value: 0.217. Predicted value: 0.188.\nTruth value: 0.687. Predicted value: 0.186.\nTruth value: 0.147. Predicted value: 0.197.\nTruth value: 0.205. Predicted value: 0.188.\nTruth value: 0.198. Predicted value: 0.197.\nTruth value: 0.131. Predicted value: 0.188.\nTruth value: 0.233. Predicted value: 0.188.\nTruth value: 0.034. Predicted value: 0.192.\nTruth value: 0.038. Predicted value: 0.208.\nTruth value: 0.373. Predicted value: 0.180.\nTruth value: 0.234. Predicted value: 0.201.\nTruth value: 0.350. Predicted value: 0.188.\nTruth value: 0.207. Predicted value: 0.188.\nTruth value: 0.087. Predicted value: 0.197.\nTruth value: 0.091. Predicted value: 0.204.\nTruth value: 0.041. Predicted value: 0.202.\nTruth value: 0.007. Predicted value: 0.197.\nTruth value: 0.250. Predicted value: 0.188.\nTruth value: 0.133. Predicted value: 0.208.\nTruth value: 0.317. Predicted value: 0.188.\nTruth value: 0.041. Predicted value: 0.186.\nTruth value: 0.188. Predicted value: 0.188.\nTruth value: 0.092. Predicted value: 0.211.\nTruth value: 0.325. Predicted value: 0.188.\nTruth value: 0.155. Predicted value: 0.195.\nTruth value: 0.675. Predicted value: 0.186.\nTruth value: 0.400. Predicted value: 0.199.\nTruth value: 0.084. Predicted value: 0.211.\nTruth value: 0.355. Predicted value: 0.188.\nTruth value: 0.220. Predicted value: 0.201.\nTruth value: 0.009. Predicted value: 0.223.\nTruth value: 0.073. Predicted value: 0.197.\nTruth value: 0.171. Predicted value: 0.186.\nTruth value: 0.076. Predicted value: 0.191.\nTruth value: 0.185. Predicted value: 0.188.\nTruth value: 0.225. Predicted value: 0.195.\nTruth value: 0.076. Predicted value: 0.211.\nTruth value: 0.128. Predicted value: 0.209.\nTruth value: 0.693. Predicted value: 0.191.\nTruth value: 0.142. Predicted value: 0.195.\nTruth value: 0.033. Predicted value: 0.213.\nTruth value: 0.108. Predicted value: 0.213.\nTruth value: 0.258. Predicted value: 0.188.\nTruth value: 0.367. Predicted value: 0.188.\nTruth value: 0.138. Predicted value: 0.200.\nTruth value: 0.200. Predicted value: 0.204.\nTruth value: 0.080. Predicted value: 0.192.\nTruth value: 0.104. Predicted value: 0.186.\nTruth value: 0.316. Predicted value: 0.201.\nTruth value: 0.262. Predicted value: 0.195.\nTruth value: 0.087. Predicted value: 0.207.\nTruth value: 0.067. Predicted value: 0.204.\nTruth value: 0.444. Predicted value: 0.188.\nTruth value: 0.200. Predicted value: 0.188.\nTruth value: 0.275. Predicted value: 0.201.\nTruth value: 0.235. Predicted value: 0.211.\nTruth value: 0.215. Predicted value: 0.188.\nTruth value: 0.097. Predicted value: 0.211.\nTruth value: 0.278. Predicted value: 0.188.\nTruth value: 0.182. Predicted value: 0.188.\nTruth value: 0.200. Predicted value: 0.188.\nTruth value: 0.269. Predicted value: 0.188.\nTruth value: 0.183. Predicted value: 0.217.\nTruth value: 0.167. Predicted value: 0.195.\nTruth value: 0.225. Predicted value: 0.188.\nTruth value: 0.250. Predicted value: 0.197.\nTruth value: 0.225. Predicted value: 0.199.\nTruth value: 0.250. Predicted value: 0.188.\nTruth value: 0.342. Predicted value: 0.199.\nTruth value: 0.348. Predicted value: 0.186.\nTruth value: 0.062. Predicted value: 0.204.\nTruth value: 0.402. Predicted value: 0.197.\nTruth value: 0.175. Predicted value: 0.197.\nTruth value: 0.212. Predicted value: 0.192.\nTruth value: 0.417. Predicted value: 0.190.\nTruth value: 0.150. Predicted value: 0.209.\nTruth value: 0.147. Predicted value: 0.197.\nTruth value: 0.092. Predicted value: 0.186.\nTruth value: 0.183. Predicted value: 0.180.\nTruth value: 0.165. Predicted value: 0.201.\nTruth value: 0.233. Predicted value: 0.188.\nTruth value: 0.164. Predicted value: 0.197.\nTruth value: 0.177. Predicted value: 0.211.\nTruth value: 0.188. Predicted value: 0.188.\nTruth value: 0.333. Predicted value: 0.195.\nTruth value: 0.067. Predicted value: 0.220.\nTruth value: 0.258. Predicted value: 0.186.\nTruth value: 0.100. Predicted value: 0.204.\nTruth value: 0.110. Predicted value: 0.207.\nTruth value: 0.067. Predicted value: 0.208.\nTruth value: 0.020. Predicted value: 0.231.\nTruth value: 0.283. Predicted value: 0.188.\nTruth value: 0.128. Predicted value: 0.197.\nTruth value: 0.240. Predicted value: 0.188.\nTruth value: 0.068. Predicted value: 0.192.\nTruth value: 0.275. Predicted value: 0.201.\nTruth value: 0.047. Predicted value: 0.202.\nTruth value: 0.167. Predicted value: 0.231.\nTruth value: 0.076. Predicted value: 0.216.\nTruth value: 0.229. Predicted value: 0.188.\nTruth value: 0.030. Predicted value: 0.213.\nTruth value: 0.542. Predicted value: 0.177.\nTruth value: 0.200. Predicted value: 0.199.\nTruth value: 0.192. Predicted value: 0.202.\nTruth value: 0.043. Predicted value: 0.200.\nTruth value: 0.082. Predicted value: 0.197.\nTruth value: 0.225. Predicted value: 0.197.\nTruth value: 0.316. Predicted value: 0.201.\nTruth value: 0.042. Predicted value: 0.188.\nTruth value: 0.093. Predicted value: 0.197.\nTruth value: 0.267. Predicted value: 0.197.\nTruth value: 0.375. Predicted value: 0.204.\nTruth value: 0.110. Predicted value: 0.197.\nTruth value: 0.108. Predicted value: 0.209.\nTruth value: 0.167. Predicted value: 0.214.\nTruth value: 0.200. Predicted value: 0.197.\nTruth value: 0.102. Predicted value: 0.204.\nTruth value: 0.141. Predicted value: 0.188.\nTruth value: 0.276. Predicted value: 0.188.\nTruth value: 0.250. Predicted value: 0.197.\nTruth value: 0.156. Predicted value: 0.192.\nTruth value: 0.010. Predicted value: 0.223.\nTruth value: 0.333. Predicted value: 0.188.\nTruth value: 0.033. Predicted value: 0.220.\nTruth value: 0.122. Predicted value: 0.208.\nTruth value: 0.105. Predicted value: 0.207.\nTruth value: 0.182. Predicted value: 0.188.\nTruth value: 0.225. Predicted value: 0.180.\nTruth value: 0.633. Predicted value: 0.186.\nTruth value: 0.020. Predicted value: 0.211.\nTruth value: 0.217. Predicted value: 0.180.\nTruth value: 0.290. Predicted value: 0.188.\nTruth value: 0.406. Predicted value: 0.188.\nTruth value: 0.125. Predicted value: 0.200.\nTruth value: 0.233. Predicted value: 0.188.\nTruth value: 0.183. Predicted value: 0.195.\nTruth value: 0.108. Predicted value: 0.208.\nTruth value: 0.240. Predicted value: 0.192.\nTruth value: 0.020. Predicted value: 0.225.\nTruth value: 0.190. Predicted value: 0.191.\nTruth value: 0.114. Predicted value: 0.186.\nTruth value: 0.367. Predicted value: 0.199.\nTruth value: 0.109. Predicted value: 0.201.\nTruth value: 0.200. Predicted value: 0.188.\nTruth value: 0.048. Predicted value: 0.234.\nTruth value: 0.061. Predicted value: 0.211.\nTruth value: 0.276. Predicted value: 0.188.\nTruth value: 0.228. Predicted value: 0.188.\nTruth value: 0.078. Predicted value: 0.202.\nTruth value: 0.375. Predicted value: 0.186.\nTruth value: 0.333. Predicted value: 0.186.\nTruth value: 0.417. Predicted value: 0.211.\nTruth value: 0.120. Predicted value: 0.188.\nTruth value: 0.246. Predicted value: 0.188.\nTruth value: 1.000. Predicted value: 0.177.\nTruth value: 0.146. Predicted value: 0.191.\nTruth value: 0.083. Predicted value: 0.213.\nTruth value: 0.083. Predicted value: 0.188.\nTruth value: 0.187. Predicted value: 0.195.\nTruth value: 0.027. Predicted value: 0.204.\nTruth value: 0.221. Predicted value: 0.188.\nTruth value: 0.030. Predicted value: 0.209.\nTruth value: 0.267. Predicted value: 0.195.\nTruth value: 0.117. Predicted value: 0.207.\nTruth value: 0.240. Predicted value: 0.186.\nTruth value: 0.261. Predicted value: 0.188.\nTruth value: 0.151. Predicted value: 0.188.\nTruth value: 0.275. Predicted value: 0.188.\nTruth value: 0.460. Predicted value: 0.199.\nTruth value: 0.031. Predicted value: 0.197.\nTruth value: 0.167. Predicted value: 0.216.\nTruth value: 0.176. Predicted value: 0.188.\nTruth value: 0.167. Predicted value: 0.211.\nTruth value: 0.208. Predicted value: 0.220.\nTruth value: 0.079. Predicted value: 0.200.\nTruth value: 0.183. Predicted value: 0.213.\nTruth value: 0.097. Predicted value: 0.202.\nTruth value: 0.165. Predicted value: 0.211.\nTruth value: 0.082. Predicted value: 0.223.\nTruth value: 0.267. Predicted value: 0.201.\nTruth value: 0.119. Predicted value: 0.191.\nTruth value: 0.275. Predicted value: 0.186.\nTruth value: 0.217. Predicted value: 0.188.\nTruth value: 0.089. Predicted value: 0.192.\nTruth value: 0.164. Predicted value: 0.211.\nTruth value: 0.200. Predicted value: 0.207.\nTruth value: 0.063. Predicted value: 0.195.\nTruth value: 0.333. Predicted value: 0.186.\nTruth value: 0.150. Predicted value: 0.209.\nTruth value: 0.114. Predicted value: 0.197.\nTruth value: 0.153. Predicted value: 0.197.\nTruth value: 0.233. Predicted value: 0.186.\nTruth value: 0.070. Predicted value: 0.207.\nTruth value: 0.106. Predicted value: 0.197.\nTruth value: 0.540. Predicted value: 0.180.\nTruth value: 0.022. Predicted value: 0.204.\nTruth value: 0.041. Predicted value: 0.213.\nTruth value: 0.047. Predicted value: 0.195.\nTruth value: 0.110. Predicted value: 0.197.\nTruth value: 0.133. Predicted value: 0.188.\nTruth value: 0.160. Predicted value: 0.200.\nTruth value: 0.097. Predicted value: 0.213.\nTruth value: 0.125. Predicted value: 0.195.\nTruth value: 0.138. Predicted value: 0.211.\nTruth value: 0.138. Predicted value: 0.195.\nTruth value: 0.321. Predicted value: 0.188.\nTruth value: 0.167. Predicted value: 0.223.\nTruth value: 0.150. Predicted value: 0.195.\nTruth value: 0.060. Predicted value: 0.202.\nTruth value: 0.036. Predicted value: 0.213.\nTruth value: 0.165. Predicted value: 0.188.\nTruth value: 0.192. Predicted value: 0.208.\nTruth value: 0.115. Predicted value: 0.188.\nTruth value: 0.090. Predicted value: 0.192.\nTruth value: 0.187. Predicted value: 0.195.\nTruth value: 0.360. Predicted value: 0.180.\nTruth value: 0.433. Predicted value: 0.188.\nTruth value: 0.200. Predicted value: 0.197.\nTruth value: 0.136. Predicted value: 0.188.\nTruth value: 0.102. Predicted value: 0.188.\nTruth value: 0.092. Predicted value: 0.216.\nTruth value: 0.183. Predicted value: 0.195.\nTruth value: 0.150. Predicted value: 0.211.\nTruth value: 0.175. Predicted value: 0.209.\nTruth value: 0.200. Predicted value: 0.199.\nTruth value: 0.087. Predicted value: 0.204.\nTruth value: 0.359. Predicted value: 0.199.\nTruth value: 0.103. Predicted value: 0.208.\nTruth value: 0.333. Predicted value: 0.188.\nTruth value: 0.348. Predicted value: 0.186.\nTruth value: 0.086. Predicted value: 0.223.\nTruth value: 0.150. Predicted value: 0.197.\nTruth value: 0.344. Predicted value: 0.211.\nTruth value: 0.109. Predicted value: 0.211.\nTruth value: 0.348. Predicted value: 0.188.\nTruth value: 0.053. Predicted value: 0.217.\nTruth value: 0.172. Predicted value: 0.195.\nTruth value: 0.255. Predicted value: 0.186.\nTruth value: 0.334. Predicted value: 0.188.\nTruth value: 0.265. Predicted value: 0.197.\nTruth value: 0.065. Predicted value: 0.211.\nTruth value: 0.267. Predicted value: 0.188.\nTruth value: 0.092. Predicted value: 0.211.\nTruth value: 0.283. Predicted value: 0.188.\nTruth value: 0.055. Predicted value: 0.197.\nTruth value: 0.278. Predicted value: 0.197.\nTruth value: 0.102. Predicted value: 0.188.\nTruth value: 0.217. Predicted value: 0.197.\nTruth value: 0.153. Predicted value: 0.211.\nTruth value: 0.192. Predicted value: 0.191.\nTruth value: 0.225. Predicted value: 0.188.\nTruth value: 0.099. Predicted value: 0.213.\nTruth value: 0.120. Predicted value: 0.204.\nTruth value: 0.233. Predicted value: 0.188.\nTruth value: 0.241. Predicted value: 0.188.\nTruth value: 0.192. Predicted value: 0.188.\nTruth value: 0.333. Predicted value: 0.186.\nTruth value: 0.151. Predicted value: 0.202.\nTruth value: 0.300. Predicted value: 0.188.\nTruth value: 0.156. Predicted value: 0.188.\nTruth value: 0.280. Predicted value: 0.180.\nTruth value: 0.017. Predicted value: 0.207.\nTruth value: 0.133. Predicted value: 0.207.\nTruth value: 0.201. Predicted value: 0.188.\nTruth value: 0.308. Predicted value: 0.192.\nTruth value: 0.076. Predicted value: 0.200.\nTruth value: 0.194. Predicted value: 0.188.\nTruth value: 0.167. Predicted value: 0.188.\nTruth value: 0.257. Predicted value: 0.188.\nTruth value: 0.234. Predicted value: 0.199.\nTruth value: 0.333. Predicted value: 0.180.\nTruth value: 0.078. Predicted value: 0.197.\nTruth value: 0.290. Predicted value: 0.186.\nTruth value: 0.070. Predicted value: 0.211.\nTruth value: 0.200. Predicted value: 0.192.\nTruth value: 0.083. Predicted value: 0.197.\nTruth value: 0.133. Predicted value: 0.191.\nTruth value: 0.258. Predicted value: 0.186.\nTruth value: 0.160. Predicted value: 0.192.\nTruth value: 0.087. Predicted value: 0.220.\nTruth value: 0.197. Predicted value: 0.182.\nTruth value: 0.013. Predicted value: 0.202.\nTruth value: 0.098. Predicted value: 0.197.\nTruth value: 0.104. Predicted value: 0.204.\nTruth value: 0.357. Predicted value: 0.188.\nTruth value: 0.133. Predicted value: 0.195.\nTruth value: 0.165. Predicted value: 0.201.\nTruth value: 0.247. Predicted value: 0.188.\nTruth value: 0.208. Predicted value: 0.209.\nTruth value: 0.217. Predicted value: 0.188.\nTruth value: 0.151. Predicted value: 0.202.\nTruth value: 0.200. Predicted value: 0.191.\nTruth value: 0.350. Predicted value: 0.188.\nTruth value: 0.158. Predicted value: 0.192.\nTruth value: 0.192. Predicted value: 0.188.\nTruth value: 0.010. Predicted value: 0.195.\nTruth value: 0.033. Predicted value: 0.200.\nTruth value: 0.242. Predicted value: 0.188.\nTruth value: 0.036. Predicted value: 0.234.\nTruth value: 0.167. Predicted value: 0.188.\nTruth value: 0.177. Predicted value: 0.195.\nTruth value: 0.181. Predicted value: 0.201.\nTruth value: 0.183. Predicted value: 0.195.\nTruth value: 0.350. Predicted value: 0.188.\nTruth value: 0.069. Predicted value: 0.209.\nTruth value: 0.167. Predicted value: 0.188.\nTruth value: 0.312. Predicted value: 0.195.\nTruth value: 0.186. Predicted value: 0.211.\nTruth value: 0.221. Predicted value: 0.188.\nTruth value: 0.158. Predicted value: 0.192.\nTruth value: 0.009. Predicted value: 0.200.\nTruth value: 0.168. Predicted value: 0.186.\nTruth value: 0.233. Predicted value: 0.188.\nTruth value: 0.234. Predicted value: 0.188.\nTruth value: 0.250. Predicted value: 0.192.\nTruth value: 0.136. Predicted value: 0.201.\nTruth value: 0.047. Predicted value: 0.207.\nTruth value: 0.043. Predicted value: 0.208.\nTruth value: 0.193. Predicted value: 0.197.\nTruth value: 0.033. Predicted value: 0.233.\nTruth value: 0.321. Predicted value: 0.188.\nTruth value: 0.112. Predicted value: 0.220.\nTruth value: 0.083. Predicted value: 0.195.\nTruth value: 0.273. Predicted value: 0.201.\nTruth value: 0.170. Predicted value: 0.211.\nTruth value: 0.267. Predicted value: 0.199.\nTruth value: 0.172. Predicted value: 0.191.\nTruth value: 0.333. Predicted value: 0.195.\nTruth value: 0.188. Predicted value: 0.188.\nTruth value: 0.076. Predicted value: 0.211.\nTruth value: 0.167. Predicted value: 0.188.\nTruth value: 0.047. Predicted value: 0.197.\nTruth value: 0.283. Predicted value: 0.186.\nTruth value: 0.255. Predicted value: 0.204.\nTruth value: 0.342. Predicted value: 0.201.\nTruth value: 0.067. Predicted value: 0.197.\nTruth value: 0.128. Predicted value: 0.197.\nTruth value: 0.131. Predicted value: 0.197.\nTruth value: 0.308. Predicted value: 0.188.\nTruth value: 0.450. Predicted value: 0.205.\nTruth value: 0.317. Predicted value: 0.191.\nTruth value: 0.017. Predicted value: 0.231.\nTruth value: 0.193. Predicted value: 0.188.\nTruth value: 0.215. Predicted value: 0.188.\nTruth value: 0.085. Predicted value: 0.202.\nTruth value: 0.275. Predicted value: 0.186.\nTruth value: 0.082. Predicted value: 0.197.\nTruth value: 0.367. Predicted value: 0.188.\nTruth value: 0.150. Predicted value: 0.209.\nTruth value: 0.275. Predicted value: 0.188.\nTruth value: 0.258. Predicted value: 0.188.\nTruth value: 0.129. Predicted value: 0.195.\nTruth value: 0.142. Predicted value: 0.209.\nTruth value: 0.182. Predicted value: 0.202.\nTruth value: 0.131. Predicted value: 0.201.\nTruth value: 0.167. Predicted value: 0.207.\nTruth value: 0.243. Predicted value: 0.188.\nTruth value: 0.359. Predicted value: 0.186.\nTruth value: 0.117. Predicted value: 0.201.\nTruth value: 0.300. Predicted value: 0.195.\nTruth value: 0.308. Predicted value: 0.186.\nTruth value: 0.062. Predicted value: 0.202.\nTruth value: 0.283. Predicted value: 0.188.\nTruth value: 0.133. Predicted value: 0.188.\nTruth value: 0.292. Predicted value: 0.188.\nTruth value: 0.267. Predicted value: 0.188.\nTruth value: 0.083. Predicted value: 0.191.\nTruth value: 0.055. Predicted value: 0.200.\nTruth value: 0.094. Predicted value: 0.202.\nTruth value: 0.300. Predicted value: 0.199.\nTruth value: 0.264. Predicted value: 0.186.\nTruth value: 0.182. Predicted value: 0.195.\nTruth value: 0.055. Predicted value: 0.197.\nTruth value: 0.293. Predicted value: 0.188.\nTruth value: 0.086. Predicted value: 0.202.\nTruth value: 0.020. Predicted value: 0.228.\nTruth value: 0.236. Predicted value: 0.190.\nTruth value: 0.037. Predicted value: 0.204.\nTruth value: 0.427. Predicted value: 0.191.\nTruth value: 0.133. Predicted value: 0.201.\nTruth value: 0.305. Predicted value: 0.211.\nTruth value: 0.152. Predicted value: 0.204.\nTruth value: 0.283. Predicted value: 0.197.\nTruth value: 0.231. Predicted value: 0.197.\nTruth value: 0.145. Predicted value: 0.195.\nTruth value: 0.189. Predicted value: 0.188.\nTruth value: 0.131. Predicted value: 0.197.\nTruth value: 0.250. Predicted value: 0.209.\nTruth value: 0.242. Predicted value: 0.188.\nTruth value: 0.110. Predicted value: 0.199.\nTruth value: 0.022. Predicted value: 0.213.\nTruth value: 0.106. Predicted value: 0.211.\nTruth value: 0.230. Predicted value: 0.209.\nTruth value: 0.253. Predicted value: 0.186.\nTruth value: 0.234. Predicted value: 0.199.\nTruth value: 0.152. Predicted value: 0.204.\nTruth value: 0.080. Predicted value: 0.200.\nTruth value: 0.053. Predicted value: 0.195.\nTruth value: 0.116. Predicted value: 0.197.\nTruth value: 0.350. Predicted value: 0.188.\nTruth value: 0.218. Predicted value: 0.197.\nTruth value: 0.120. Predicted value: 0.202.\nTruth value: 0.258. Predicted value: 0.188.\nTruth value: 0.175. Predicted value: 0.188.\nTruth value: 0.211. Predicted value: 0.211.\nTruth value: 0.017. Predicted value: 0.209.\nTruth value: 0.267. Predicted value: 0.195.\nTruth value: 0.036. Predicted value: 0.213.\nTruth value: 0.196. Predicted value: 0.201.\nTruth value: 0.195. Predicted value: 0.192.\nTruth value: 0.076. Predicted value: 0.195.\nTruth value: 0.225. Predicted value: 0.188.\nTruth value: 0.303. Predicted value: 0.201.\nTruth value: 0.225. Predicted value: 0.195.\nTruth value: 0.133. Predicted value: 0.183.\nTruth value: 0.010. Predicted value: 0.217.\nTruth value: 0.292. Predicted value: 0.180.\nTruth value: 0.367. Predicted value: 0.188.\nTruth value: 0.250. Predicted value: 0.177.\nTruth value: 0.188. Predicted value: 0.199.\nTruth value: 0.151. Predicted value: 0.188.\nTruth value: 0.155. Predicted value: 0.211.\nTruth value: 0.383. Predicted value: 0.188.\nTruth value: 0.148. Predicted value: 0.186.\nTruth value: 0.142. Predicted value: 0.211.\nTruth value: 0.383. Predicted value: 0.183.\nTruth value: 0.208. Predicted value: 0.197.\nTruth value: 0.064. Predicted value: 0.197.\nTruth value: 0.101. Predicted value: 0.192.\nTruth value: 0.120. Predicted value: 0.211.\nTruth value: 0.367. Predicted value: 0.201.\nTruth value: 0.275. Predicted value: 0.201.\nTruth value: 0.308. Predicted value: 0.201.\nTruth value: 0.750. Predicted value: 0.195.\nTruth value: 0.129. Predicted value: 0.207.\nTruth value: 0.065. Predicted value: 0.197.\nTruth value: 0.167. Predicted value: 0.226.\nTruth value: 0.215. Predicted value: 0.201.\nTruth value: 0.146. Predicted value: 0.195.\nTruth value: 0.283. Predicted value: 0.188.\nTruth value: 0.175. Predicted value: 0.201.\nTruth value: 0.031. Predicted value: 0.207.\nTruth value: 0.128. Predicted value: 0.200.\nTruth value: 0.252. Predicted value: 0.195.\nTruth value: 0.245. Predicted value: 0.202.\nTruth value: 0.133. Predicted value: 0.207.\nTruth value: 0.033. Predicted value: 0.195.\nTruth value: 0.300. Predicted value: 0.201.\nTruth value: 0.032. Predicted value: 0.201.\nTruth value: 0.250. Predicted value: 0.195.\nTruth value: 0.392. Predicted value: 0.186.\nTruth value: 0.433. Predicted value: 0.204.\nTruth value: 0.118. Predicted value: 0.202.\nTruth value: 0.148. Predicted value: 0.202.\nTruth value: 0.109. Predicted value: 0.211.\nTruth value: 0.151. Predicted value: 0.188.\nTruth value: 0.106. Predicted value: 0.211.\nTruth value: 0.193. Predicted value: 0.201.\nTruth value: 0.333. Predicted value: 0.197.\nTruth value: 0.005. Predicted value: 0.213.\nTruth value: 0.051. Predicted value: 0.204.\nTruth value: 0.210. Predicted value: 0.188.\nTruth value: 0.200. Predicted value: 0.211.\nTruth value: 0.078. Predicted value: 0.195.\nTruth value: 0.016. Predicted value: 0.213.\nTruth value: 0.097. Predicted value: 0.207.\nTruth value: 0.227. Predicted value: 0.201.\nTruth value: 0.124. Predicted value: 0.202.\nTruth value: 0.292. Predicted value: 0.188.\nTruth value: 0.128. Predicted value: 0.197.\nTruth value: 0.076. Predicted value: 0.207.\nTruth value: 0.166. Predicted value: 0.188.\nTruth value: 0.267. Predicted value: 0.188.\nTruth value: 0.151. Predicted value: 0.188.\nTruth value: 0.132. Predicted value: 0.186.\nTruth value: 0.271. Predicted value: 0.188.\nTruth value: 0.033. Predicted value: 0.209.\nTruth value: 0.188. Predicted value: 0.202.\nTruth value: 0.147. Predicted value: 0.201.\nTruth value: 0.106. Predicted value: 0.192.\nTruth value: 0.250. Predicted value: 0.188.\nTruth value: 0.221. Predicted value: 0.201.\nTruth value: 0.060. Predicted value: 0.202.\nTruth value: 0.073. Predicted value: 0.197.\nTruth value: 0.350. Predicted value: 0.188.\nTruth value: 0.250. Predicted value: 0.201.\nTruth value: 0.015. Predicted value: 0.209.\nTruth value: 0.166. Predicted value: 0.195.\nTruth value: 0.342. Predicted value: 0.201.\nTruth value: 0.007. Predicted value: 0.220.\nTruth value: 0.100. Predicted value: 0.209.\nTruth value: 0.147. Predicted value: 0.197.\nTruth value: 0.169. Predicted value: 0.188.\nTruth value: 0.056. Predicted value: 0.211.\nTruth value: 0.105. Predicted value: 0.216.\nTruth value: 0.204. Predicted value: 0.208.\nTruth value: 0.117. Predicted value: 0.202.\nTruth value: 0.117. Predicted value: 0.202.\nTruth value: 0.050. Predicted value: 0.211.\nTruth value: 0.072. Predicted value: 0.211.\nTruth value: 0.151. Predicted value: 0.188.\nTruth value: 0.145. Predicted value: 0.213.\nTruth value: 0.175. Predicted value: 0.188.\nTruth value: 0.164. Predicted value: 0.211.\nTruth value: 0.217. Predicted value: 0.202.\nTruth value: 0.705. Predicted value: 0.202.\nTruth value: 0.254. Predicted value: 0.188.\nTruth value: 0.059. Predicted value: 0.195.\nTruth value: 0.250. Predicted value: 0.188.\nTruth value: 0.250. Predicted value: 0.199.\nTruth value: 0.333. Predicted value: 0.195.\nTruth value: 0.151. Predicted value: 0.188.\nTruth value: 0.352. Predicted value: 0.188.\nTruth value: 0.383. Predicted value: 0.188.\nTruth value: 0.175. Predicted value: 0.195.\nTruth value: 0.065. Predicted value: 0.197.\nTruth value: 0.177. Predicted value: 0.188.\nTruth value: 0.027. Predicted value: 0.228.\nTruth value: 0.321. Predicted value: 0.188.\nTruth value: 0.159. Predicted value: 0.201.\nTruth value: 0.010. Predicted value: 0.213.\nTruth value: 0.133. Predicted value: 0.204.\nTruth value: 0.217. Predicted value: 0.211.\nTruth value: 0.205. Predicted value: 0.188.\nTruth value: 0.131. Predicted value: 0.197.\nTruth value: 0.131. Predicted value: 0.211.\nTruth value: 0.121. Predicted value: 0.204.\nTruth value: 0.092. Predicted value: 0.221.\nTruth value: 0.117. Predicted value: 0.204.\nTruth value: 0.184. Predicted value: 0.188.\nTruth value: 0.126. Predicted value: 0.195.\nTruth value: 0.100. Predicted value: 0.186.\nTruth value: 0.267. Predicted value: 0.191.\nTruth value: 0.196. Predicted value: 0.211.\nTruth value: 0.211. Predicted value: 0.188.\nTruth value: 0.132. Predicted value: 0.183.\nTruth value: 0.106. Predicted value: 0.207.\nTruth value: 0.228. Predicted value: 0.188.\nTruth value: 0.163. Predicted value: 0.211.\nTruth value: 0.167. Predicted value: 0.188.\nTruth value: 0.138. Predicted value: 0.195.\nTruth value: 0.217. Predicted value: 0.186.\nTruth value: 0.128. Predicted value: 0.217.\nTruth value: 0.170. Predicted value: 0.188.\nTruth value: 0.283. Predicted value: 0.188.\nTruth value: 0.123. Predicted value: 0.207.\nTruth value: 0.207. Predicted value: 0.211.\nTruth value: 0.167. Predicted value: 0.217.\nTruth value: 0.097. Predicted value: 0.213.\n"}]},{"source":"Note: The code above trains a neural network model using PyTorch to predict salaries based on a dataset of employee features. The dataset is loaded into an instance of the MyDataset class and a DataLoader is created to load the data in batches. The neural network model consists of two linear layers with sigmoid activation function between them. The mean squared error loss function and stochastic gradient descent optimizer are used to train the model for 10 epochs. The show_results function is then called to display the predicted and ground truth salaries for each data point in the dataset.","metadata":{},"cell_type":"markdown","id":"262bd2e4-6a0c-417a-b6ab-787bbd8294b6"},{"source":"### 6. Test the trained network on a separate dataset to evaluate performance","metadata":{},"cell_type":"markdown","id":"c8af21d3-51c8-4f21-998a-87621d4dbc0c"},{"source":"# Set the model to evaluation mode\nmodel.eval()\nvalidation_loss = 0.0\nwith torch.no_grad():\n  for data in validationloader:\n      outputs = model(data[0])\n      loss = criterion(outputs, data[1])\n      # Sum the current loss to the validation_loss variable\n      validation_loss += loss.item()\n# Calculate the mean loss value\nvalidation_loss_epoch = validation_loss / len(validationloader)\n# Set the model back to training mode\nmodel.train()","metadata":{"executionTime":33,"lastSuccessfullyExecutedCode":"# Set the model to evaluation mode\nmodel.eval()\nvalidation_loss = 0.0\nwith torch.no_grad():\n  for data in validationloader:\n      outputs = model(data[0])\n      loss = criterion(outputs, data[1])\n      # Sum the current loss to the validation_loss variable\n      validation_loss += loss.item()\n# Calculate the mean loss value\nvalidation_loss_epoch = validation_loss / len(validationloader)\n# Set the model back to training mode\nmodel.train()"},"cell_type":"code","id":"0b3d0f6d-52fa-4549-bbe9-f5d62e9ba53e","execution_count":null,"outputs":[{"output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m validation_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 5\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mvalidationloader\u001b[49m:\n\u001b[1;32m      6\u001b[0m       outputs \u001b[38;5;241m=\u001b[39m model(data[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      7\u001b[0m       loss \u001b[38;5;241m=\u001b[39m criterion(outputs, data[\u001b[38;5;241m1\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'validationloader' is not defined"],"ename":"NameError","evalue":"name 'validationloader' is not defined"}]},{"source":"import torchmetrics\n\n# Create accuracy metric using torch metrics\nmetric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=3)\nfor data in dataloader:\n    features, labels = data\n    outputs = model(features)\n    \n    # Calculate accuracy over the batch\n    acc = metric(outputs.softmax(dim=-1), labels.argmax(dim=-1))\n    \n# Calculate accuracy over the whole epoch\nacc = metric.compute()\n\n# Reset the metric for the next epoch \nmetric.reset()","metadata":{"executionCancelledAt":1681463765105},"cell_type":"code","id":"216dcbf3-043f-4216-a4c1-c1b231804360","execution_count":null,"outputs":[]},{"source":"### Improve performance","metadata":{},"cell_type":"markdown","id":"3e2e1463-99f5-4726-8ed1-4a4a54ab2b4f"},{"source":"Steps to maximize performance: overfit the training set, reduce overfitting, fine-tune the hyperparamters","metadata":{},"cell_type":"markdown","id":"e429fb3d-6f7a-4b4a-95e6-aa52ac555405"},{"source":"# overfit the training set\n\nfeatures, labels = next(iter(trainloader))\nfor i in range(1e3):\n    outputs = model(features)\n    loss = criterion(outputs, labels)\n    loss.backward()\n    optimizer.step()","metadata":{"executionCancelledAt":1681463765125},"cell_type":"code","id":"b7b9fa24-4115-4941-ae14-221accab6335","execution_count":null,"outputs":[]},{"source":"# reduce overfitting (the model does not generalize to unseen data)","metadata":{"executionCancelledAt":1681463765156},"cell_type":"code","id":"d27c73e6-a6e7-4cea-b3b6-784ac7ae84c6","execution_count":179,"outputs":[]},{"source":"# 1. If the dataset in not large enought, get more data or use data augmentation\n\nfrom torchvision import transforms\n\n# Create a data augmentation strategy using at least one transform\naugmentation = nn.Sequential(transforms.RandomHorizontalFlip(p=0.5))\n\n# Create a data augmentation strategy using all three transforms.\naugmentation = nn.Sequential(transforms.RandomHorizontalFlip(p=0.5),\n                             transforms.RandomResizedCrop(size=32, scale=(0.3, 1.5)),\n                             transforms.RandomRotation(degrees=20))","metadata":{"executionCancelledAt":1681463765174},"cell_type":"code","id":"7677692c-f4be-4d70-942d-dfa2cac69a21","execution_count":141,"outputs":[]},{"source":"# 2. If the model has too much capacity, reduce model size or add dropout\nmodel = nn.Sequential(nn.Linear(8, 4), nn.ReLU(), nn.Dropout(p=0.5))\nfeatures = torch.randn((1, 8))\n#model(i)\n\n#Behaves differently during training and evaluation. Do not forget to switch modes using model.train() and model.eval()","metadata":{"executionCancelledAt":1681463765201},"cell_type":"code","id":"76862495-af3e-44f7-bae4-cbaba2a61d1c","execution_count":161,"outputs":[]},{"source":"# 3. If weights are too large, weight decay\noptimizer = optim.SGD(model.parameters(), lr=1e-3, weight_decay=1e-4)\n\n#weight_decay parameter:values between 0 and 1. Typically, a very small value (10^-4 ). the higher the parameter, the less likely the model is to overfit.","metadata":{"executionCancelledAt":1681463765218},"cell_type":"code","id":"dde10ada-9dd4-4782-8473-5d9b864abe3c","execution_count":162,"outputs":[]},{"source":"# fine-tune hyperparameters","metadata":{"executionCancelledAt":1681463765239},"cell_type":"code","id":"66db84b9-6ab5-4c9c-9a4c-6818d552f1e4","execution_count":180,"outputs":[]},{"source":"# implement random search\n\nvalues = []\nfor idx in range(10):\n    # Randomly sample a learning rate factor between 0.01 and 0.0001\n    factor = np.random.uniform(2, 6)\n    lr = 10 ** -factor\n    \n    # Randomly sample a momentum between 0.85 and 0.99\n    momentum = np.random.uniform(0.85, 0.99)\n    \n    values.append((lr, momentum))","metadata":{"executionCancelledAt":1681463765281},"cell_type":"code","id":"64c32eaa-ff10-4fa2-8826-dc64e13b8231","execution_count":196,"outputs":[]},{"source":"# create the best model  \nmodel = nn.Sequential(transforms.Normalize(mean, std),\n                      transforms.RandomHorizontalFlip(p=0.5),\n                      transforms.RandomResizedCrop(size=32, scale=(0.8, 1.2)),\n                      transforms.RandomRotation(degrees=10),\n                      nn.Flatten(),\n                      nn.Linear(3072, 3))\n\n# Pick a learning rate\nlr = 0.01\ntrain_and_evaluate(model, learning_rate=lr)\n\n# Adjust other parameters\ntrain_and_evaluate(model, learning_rate=0.01, num_epochs=20, momentum=0.9, weight_decay=1e-4)","metadata":{"executionCancelledAt":1681463765301},"cell_type":"code","id":"c83f2e38-c17f-4fd0-91e4-6567fe3f9999","execution_count":null,"outputs":[]},{"source":"# More about NN","metadata":{},"cell_type":"markdown","id":"35027f9a-dec2-4b82-ac28-cd834c5c45e8"},{"source":"### Activation functions","metadata":{},"cell_type":"markdown","id":"35f72d4c-acd3-4152-bf12-02c96572992c"},{"source":"# Implement ReLU in NumPy\ndef relu_numpy(x):\n  # Implement the ReLU function\n  return np.maximum(x,0)\n\n# Create a ReLU function with PyTorch\nrelu_pytorch = nn.ReLU()\n\n# Calculate the gradient of the ReLU function for x\nx = torch.tensor(-1.0, requires_grad=True)\ny = relu_pytorch(x)\ny.backward()\ngradient = x.grad\n\n# Implementing leaky ReLU\ndef leaky_relu_python(x, slope):\n  # Implement the leaky_relu function\n  if x >=0:\n    return x\n  else:\n    return x * slope\n\n# Create a leaky relu function in PyTorch\nleaky_relu_pytorch = nn.LeakyReLU(negative_slope = 0.05)\n\ny = torch.tensor(-2.0)\n# Call the above function of the tensor y\noutput = leaky_relu_pytorch(y)\n","metadata":{"executionCancelledAt":1681463765311},"cell_type":"code","id":"d697a262-ae63-4684-8bd2-08edb5aefe25","execution_count":79,"outputs":[]},{"source":"### Model capacity","metadata":{},"cell_type":"markdown","id":"5532a42c-c8a2-46ac-8d4b-2c16c6f57a85"},{"source":"def calculate_capacity(model):\n  total = 0\n  for p in model.parameters():\n    total += p.numel()\n  return total\n\nn_features = 8\nn_classes = 2\n\n# Create a neural network with less than 120 parameters\nmodel = nn.Sequential(nn.Linear(n_features, 8),\n                      nn.Linear(8, 4),\n                      nn.Linear(4, n_classes))\nprint(calculate_capacity(model))\n\n# Create a neural network with more than 120 parameters\nmodel = nn.Sequential(nn.Linear(n_features, 8),\n                      nn.Linear(8, 6),\n                      nn.Linear(6, n_classes))\ncalculate_capacity(model)","metadata":{"executionCancelledAt":1681463765330},"cell_type":"code","id":"14fb138f-69f1-44ba-8aa7-4a8c2df1c3af","execution_count":80,"outputs":[]},{"source":"### Learning rate and momentum","metadata":{},"cell_type":"markdown","id":"b194bbe0-5b94-44f6-8087-810ac9f3e75b"},{"source":"SGD has two parameters: learning rate that controls the step size and momentul that controls the inertia of the optimizer. Bad values can lead to long raining time and bad overall performance (poor accuracy).\n\n- Learning rate: controls the step size; too small leads to long training times; too high leads to poor performance; typical values between 10^-2 and 10^-4.\n- Momentum: controls the inertia; null momentum can lead to the optimizer being stuck in a local minimum; non-null momentum can help find the function minimum; typical values between 0.85 and 0.99.","metadata":{},"cell_type":"markdown","id":"daa47c10-42e7-4a3e-b124-78c5fedc53f3"},{"source":"### Layer initialization, transfer learning and fine-tuning","metadata":{},"cell_type":"markdown","id":"f3d024dd-8e60-4d7d-8052-4c89a3ff70b2"},{"source":"Fine-tuning process: find a model trained on a similar task; load pre-trained weights; freeze (or not) some of the layers in the model; train with a smaller lerning rate; look at the loss values and see if the learning rate needs to be adjusted","metadata":{},"cell_type":"markdown","id":"82829d67-7a00-47ca-83f0-5765a332a812"},{"source":"# Layer initialization (weights are initialized to small values)\nlayer = nn.Linear(64, 128)\nnn.init.uniform_(layer.weight)\nprint(layer.weight.min(), layer.weight.max())\n\n# Transfer learning: reusing a model trained on a first task for a second similar task, to accelerate the training process.\ntorch.save(layer, 'layer.pth')\nnew_layer = torch.load('layer.pth')\n\n# Fine-tuning (A type of transfer learning; Smaller learning rate; Not every layer is trained (we freeze some of them); Rule of thumb: freeze early layers of network and fine-tune layers closer to output layer)\nmodel = nn.Sequential(nn.Linear(64, 128), nn.Linear(128, 256))\nfor name, param in model.named_parameters():\n    # Check if the parameters belong to the first layer\n    if name == '0.weight':\n        # Freeze the parameters\n        param.requires_grad = False","metadata":{"executionCancelledAt":1681463765345},"cell_type":"code","id":"8bf64b36-0c01-46f9-b86c-1e7bf52c3de2","execution_count":81,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}